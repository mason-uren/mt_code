{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def searchForFocus(filename, substring):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read()\n",
    "        location = data.find(substring)\n",
    "        croppedStr = data[location+len(substring):]\n",
    "        # Split at spaces and find first number\n",
    "        for word in croppedStr.split(): # Split at spaces\n",
    "            # Delete any commas    \n",
    "            word = word.replace(',', \"\")\n",
    "            try:\n",
    "                focusPosition = int(word)\n",
    "                return focusPosition\n",
    "            except ValueError:\n",
    "                continue\n",
    "    file.close()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    # ids indicates what subfolders (samples) to access\n",
    "    def __init__(self, foldername, subfolderPrefix, ids):\n",
    "        self.foldername = foldername\n",
    "        self.subfolderPrefix = subfolderPrefix\n",
    "        self.ids = ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sampleFoldername = self.foldername + '/' + self.subfolderPrefix + str(index)\n",
    "        \n",
    "# Moved to separate createAF file        \n",
    "#         # Load in image as [0,1] array\n",
    "#         image = cv2.imread(sampleFoldername + '/before' + str(index) + '.tif', 0) * 1 / 255.0\n",
    "        \n",
    "#         # Shift it so is from [-1,1]\n",
    "#         image *= 2\n",
    "#         image -= 1\n",
    "#         X = torch.from_numpy(image)\n",
    "#         X = X.unsqueeze(0) # Add fake first dimension to specify 1-channel\n",
    "\n",
    "#         # Get the label\n",
    "#         beforeFocus = searchForFocus(sampleFoldername + '/focusInfo.txt', 'before focus: ')\n",
    "#         afterFocus = searchForFocus(sampleFoldername + '/focusInfo.txt', 'after focus: ')\n",
    "        \n",
    "#         y = afterFocus - beforeFocus\n",
    "        \n",
    "        X = torch.load(sampleFoldername + '/X')\n",
    "        y = torch.load(sampleFoldername + '/y')\n",
    "        \n",
    "        return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "params = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}\n",
    "\n",
    "# Randomly partition the full list into a training set and validation set\n",
    "numSamples = 100 # total number of samples collected\n",
    "frac = 1/5 # fraction to be validation\n",
    "\n",
    "# Fix the seed for comparison\n",
    "np.random.seed(0)\n",
    "permutedIds = np.random.permutation(range(numSamples))\n",
    "splitPoint = int((1-frac) * len(permutedIds))\n",
    "trainingIds = permutedIds[:splitPoint]\n",
    "valIds = permutedIds[splitPoint:]\n",
    "testIds = range(numSamples, 200)\n",
    "\n",
    "training_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', trainingIds)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', valIds)\n",
    "#validation_generator = torch.utils.data.DataLoader(validation_set, **params)\n",
    "\n",
    "test_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', testIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6004, 7920])\n",
      "-87\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X, y = training_set.__getitem__(1)\n",
    "\n",
    "    def imshow(img,wait):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = np.squeeze(img.numpy())\n",
    "        width = int(0.15 * npimg.shape[1])\n",
    "        height = int(0.15 * npimg.shape[0])\n",
    "        cv2.imshow(\"Hi\",cv2.resize(npimg, (width, height)))\n",
    "        cv2.waitKey(wait)\n",
    "        cv2.destroyAllWindows()\n",
    "    imshow(X, 1000)\n",
    "    print(X.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider placing dropout layers after conv2d layers (conv2d -> batchnorm2d -> leakyReLU -> dropout(p=0.1))\n",
    "# And also place after fully connected layers (linear -> leakyReLU -> dropout(p=0.3))\n",
    "# TODO: Should actually figure out appropriate amount of padding for layers \n",
    "\n",
    "net = nn.Sequential(\n",
    "    # First, let's try to \"downsample\" by using a large stride with a one-channel convolution\n",
    "    nn.Conv2d(1, 1, kernel_size=7, stride=3),\n",
    "    nn.Conv2d(1, 4, kernel_size=5, stride=1),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Dropout2d(0.1),\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=1),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Dropout2d(0.1),\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=1),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Dropout2d(0.1),\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=1),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Dropout2d(0.1),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Dropout2d(0.1),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(252, 100),\n",
    "    #nn.BatchNorm1d(100),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    #nn.Dropout(0.3),\n",
    "    nn.Linear(100, 10),\n",
    "    #nn.BatchNorm1d(10),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    #nn.Dropout(0.3),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 7, 7])\n",
      "torch.Size([1])\n",
      "torch.Size([4, 1, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 3, 3])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([100, 252])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0649, -0.1221,  0.0271,  0.0571, -0.1025, -0.1066, -0.0066],\n",
      "          [-0.1292,  0.0231, -0.0684, -0.1060,  0.1351, -0.0822, -0.0761],\n",
      "          [-0.0549, -0.0369,  0.0223,  0.1170, -0.0348, -0.0443, -0.0077],\n",
      "          [ 0.1146, -0.1058, -0.1262, -0.0412,  0.0644,  0.0782, -0.0650],\n",
      "          [-0.0231,  0.0069,  0.0009, -0.0057,  0.0257,  0.1331, -0.1190],\n",
      "          [-0.1303,  0.1106,  0.0874,  0.0949, -0.0014,  0.0278, -0.0407],\n",
      "          [ 0.0161,  0.1418, -0.0711, -0.1017, -0.0423, -0.0199,  0.0061]]]],\n",
      "       device='cuda:0')\n",
      "tensor([0.1390], device='cuda:0')\n",
      "tensor([[[[-0.1124,  0.0825,  0.0668,  0.1620, -0.1714],\n",
      "          [-0.0717,  0.0933,  0.0316, -0.0484,  0.1392],\n",
      "          [ 0.1029, -0.0790, -0.1066, -0.1478, -0.0995],\n",
      "          [ 0.0063, -0.1082,  0.0782, -0.0519,  0.1547],\n",
      "          [ 0.1026,  0.0992, -0.1950, -0.0404,  0.1742]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1650, -0.0886, -0.1122,  0.0757, -0.1773],\n",
      "          [ 0.1053, -0.0867,  0.0573,  0.1418,  0.0663],\n",
      "          [-0.0112,  0.1021, -0.0864,  0.1758,  0.0128],\n",
      "          [ 0.1286,  0.0732, -0.1409, -0.1392,  0.0323],\n",
      "          [-0.1427,  0.0358, -0.0468, -0.1359, -0.0285]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0916, -0.1252,  0.0857,  0.0586,  0.1007],\n",
      "          [-0.0382,  0.1179,  0.1904, -0.0349,  0.1070],\n",
      "          [-0.1624, -0.0116,  0.0282, -0.1074, -0.0167],\n",
      "          [-0.1691, -0.0410, -0.0736, -0.1079, -0.0566],\n",
      "          [-0.1711,  0.0744,  0.0830, -0.1944, -0.0971]]],\n",
      "\n",
      "\n",
      "        [[[-0.1659, -0.1475,  0.0823,  0.0803, -0.1013],\n",
      "          [ 0.1494,  0.0472, -0.1578,  0.0345,  0.1952],\n",
      "          [ 0.1181, -0.0646, -0.0733, -0.1157, -0.0981],\n",
      "          [ 0.1420,  0.0537,  0.0389,  0.1283,  0.1583],\n",
      "          [-0.1028,  0.1471,  0.0156, -0.1757, -0.1563]]]], device='cuda:0')\n",
      "tensor([ 0.1754,  0.0194,  0.1082, -0.1232], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[-6.4016e-02, -9.3459e-02, -8.0125e-02, -6.3984e-03,  8.3344e-02],\n",
      "          [-6.7327e-02,  6.5761e-02, -1.6778e-03, -3.1859e-02,  9.2111e-02],\n",
      "          [-1.7267e-02,  2.3535e-02, -2.6006e-02, -6.2238e-02, -2.1250e-02],\n",
      "          [ 7.7208e-02,  6.9765e-02,  5.4703e-02,  1.3260e-02,  8.1327e-02],\n",
      "          [-9.4358e-03,  7.1166e-02,  9.4040e-02, -4.0828e-02,  5.0220e-02]],\n",
      "\n",
      "         [[ 4.0607e-02, -4.7079e-02, -6.9501e-02,  2.8224e-03,  4.1166e-02],\n",
      "          [ 7.5061e-02, -7.7629e-02,  3.6192e-02,  5.6050e-02,  8.5799e-02],\n",
      "          [ 1.9345e-02,  1.0478e-02,  4.5072e-02, -7.5253e-02,  2.7595e-02],\n",
      "          [-5.2569e-02,  4.6820e-02,  6.0974e-03, -1.2944e-02,  6.3541e-02],\n",
      "          [ 6.3083e-02,  1.0770e-02,  1.8847e-02,  7.9265e-02,  4.3074e-02]],\n",
      "\n",
      "         [[ 4.1286e-02,  9.1097e-02, -3.2092e-02,  5.5901e-02,  2.7495e-02],\n",
      "          [-4.1842e-02, -8.4473e-02,  3.2508e-02, -2.0713e-02, -4.7002e-03],\n",
      "          [ 9.0086e-02,  3.4316e-02, -1.9362e-02, -1.0821e-02, -6.8588e-02],\n",
      "          [ 4.4326e-02, -9.9707e-02,  1.6169e-02,  1.8307e-02, -8.1839e-02],\n",
      "          [ 5.0586e-02, -9.7485e-02,  7.9097e-02, -5.5381e-02,  8.0133e-02]],\n",
      "\n",
      "         [[ 1.3569e-02, -2.7866e-02,  6.0122e-02, -3.0215e-02,  6.8779e-03],\n",
      "          [-8.6633e-02, -2.2333e-02,  4.7878e-02,  7.6776e-02,  6.6156e-02],\n",
      "          [ 7.7247e-02,  1.7032e-03,  2.0548e-02, -7.7475e-03,  1.1143e-02],\n",
      "          [-8.7854e-02,  7.3564e-02, -6.3084e-02, -7.8834e-02, -6.2767e-02],\n",
      "          [-6.5363e-02, -8.0829e-04, -1.4139e-02, -9.3587e-02, -5.3537e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3643e-02,  6.3022e-02, -9.2274e-02, -6.4274e-02, -4.4803e-02],\n",
      "          [-3.7476e-02,  1.5832e-02, -2.3143e-02,  4.9902e-02,  1.5712e-03],\n",
      "          [-1.3127e-03, -3.0226e-02, -2.6408e-02,  7.5786e-02,  3.4124e-02],\n",
      "          [-3.2550e-02,  4.2446e-03,  2.8525e-02,  3.9431e-02,  1.5105e-02],\n",
      "          [ 7.4187e-02,  8.2821e-02,  6.8849e-02, -5.8315e-02, -5.7549e-02]],\n",
      "\n",
      "         [[ 7.0017e-02, -7.4146e-02, -8.7984e-02, -5.3105e-02,  5.6098e-02],\n",
      "          [-6.8924e-03, -4.4858e-02,  4.1239e-02,  4.0105e-02,  4.1344e-03],\n",
      "          [-8.0991e-02, -8.2687e-03, -9.9706e-02,  2.2279e-03,  3.8131e-02],\n",
      "          [ 7.5320e-03,  3.8064e-02,  7.3875e-02, -7.5543e-02, -2.1968e-02],\n",
      "          [ 1.3161e-02, -9.1520e-02, -3.6268e-02, -9.4365e-02, -6.8824e-02]],\n",
      "\n",
      "         [[-1.7248e-02,  6.4369e-02, -5.0529e-02, -7.3320e-02, -8.4009e-02],\n",
      "          [ 1.8394e-02, -8.5059e-02, -7.7288e-02,  6.9236e-02, -8.5664e-02],\n",
      "          [ 4.6769e-02,  7.8124e-02,  4.5363e-02,  1.2680e-02, -7.5317e-03],\n",
      "          [-8.8767e-02,  7.6736e-02, -4.7014e-02, -4.7710e-02, -8.0068e-02],\n",
      "          [ 6.5551e-02,  4.8917e-02, -9.3721e-03,  4.9047e-02, -8.4641e-02]],\n",
      "\n",
      "         [[-1.3664e-02,  8.2299e-02,  8.8165e-03, -2.2010e-02, -9.7241e-02],\n",
      "          [ 4.1321e-02,  8.3176e-02, -6.7124e-02,  2.0630e-02, -4.7536e-02],\n",
      "          [ 3.1220e-02,  8.1270e-03, -5.6925e-03, -1.0158e-02, -8.2888e-02],\n",
      "          [ 5.6624e-06,  5.7940e-02, -9.4810e-02,  6.0213e-02,  2.6188e-02],\n",
      "          [-8.4383e-02,  9.7416e-02, -8.0834e-02,  2.5098e-02, -4.3049e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4406e-02, -2.1339e-02, -6.1210e-02,  3.5831e-02,  8.4978e-03],\n",
      "          [ 2.1037e-02,  1.8104e-02, -5.5929e-02, -7.2916e-02, -3.6367e-02],\n",
      "          [-4.8206e-03, -6.6811e-02,  7.6215e-02, -2.6083e-02,  8.6970e-02],\n",
      "          [-1.5543e-02, -1.7774e-02, -3.2102e-02,  8.3237e-02, -9.7459e-02],\n",
      "          [-4.7495e-02,  4.7994e-02, -1.7285e-03,  9.3025e-02, -1.1928e-04]],\n",
      "\n",
      "         [[-1.5017e-02,  1.4546e-02,  1.6920e-02,  3.1730e-02, -9.7155e-02],\n",
      "          [-1.3792e-02, -1.6540e-02, -7.5176e-03, -8.7098e-02,  2.0228e-02],\n",
      "          [ 9.6511e-03, -2.8969e-02, -5.7544e-02,  2.0532e-02, -5.2712e-02],\n",
      "          [-3.4644e-02, -7.1014e-03,  7.4675e-02,  7.7697e-02,  8.6512e-02],\n",
      "          [-5.9960e-02, -9.2498e-02, -1.6429e-02, -4.6955e-02,  2.2146e-03]],\n",
      "\n",
      "         [[ 8.0910e-02,  8.8984e-02,  9.2766e-02,  5.6823e-02,  1.2446e-03],\n",
      "          [-1.5626e-02,  9.1773e-02, -9.1879e-02, -1.0500e-02, -1.3867e-02],\n",
      "          [-5.2923e-02, -9.3315e-02, -8.9757e-03,  5.7899e-02,  1.3537e-02],\n",
      "          [ 1.4480e-02, -8.8100e-02,  5.6191e-02, -2.5682e-02,  1.9888e-02],\n",
      "          [-5.4842e-02, -1.5930e-03,  8.9204e-02,  8.7378e-02, -1.5761e-02]],\n",
      "\n",
      "         [[ 9.7321e-02,  8.6303e-02, -9.0468e-02, -5.0939e-04,  1.9563e-02],\n",
      "          [-5.1646e-02,  4.1967e-02,  9.6382e-02, -4.6052e-02,  6.2510e-02],\n",
      "          [-2.2779e-02,  9.3156e-02,  6.1248e-02, -3.9957e-02,  6.1077e-02],\n",
      "          [ 9.7492e-03,  8.6058e-02, -9.4218e-02,  3.2065e-02, -2.0300e-02],\n",
      "          [ 4.0793e-02, -2.8840e-02, -9.1825e-02, -7.5161e-02, -9.3115e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.4271e-02, -4.6066e-02, -7.9593e-02, -4.5916e-03,  3.2986e-02],\n",
      "          [-4.5128e-02, -9.1988e-02, -3.2408e-02, -7.0464e-02,  8.2371e-03],\n",
      "          [-5.0404e-02,  8.1051e-02,  8.1641e-02,  5.1862e-02, -3.2583e-02],\n",
      "          [ 1.3296e-02,  7.4969e-02,  9.6239e-02,  4.4977e-02,  5.9531e-02],\n",
      "          [-9.1884e-02, -4.3898e-02, -8.1549e-02, -9.6747e-02,  3.0552e-02]],\n",
      "\n",
      "         [[-3.2601e-02, -5.7407e-02, -9.0816e-02,  4.6975e-02, -1.2158e-02],\n",
      "          [ 2.4153e-02, -7.2372e-02,  8.5364e-02,  5.5433e-02,  8.8038e-02],\n",
      "          [ 4.1947e-02, -3.4755e-02,  5.0585e-02, -3.4021e-02, -8.4123e-02],\n",
      "          [-9.8415e-02,  5.6029e-02,  3.9043e-02,  9.2597e-02,  4.4832e-02],\n",
      "          [ 3.8157e-02,  7.7401e-02,  2.0160e-02,  5.5874e-02,  6.5160e-02]],\n",
      "\n",
      "         [[-3.6814e-02,  5.4544e-02, -4.8544e-02,  5.3367e-02, -4.6932e-02],\n",
      "          [ 5.0465e-02,  8.0133e-02,  5.2054e-02,  4.3211e-02, -9.8431e-02],\n",
      "          [-8.9022e-02,  5.8618e-02,  2.9401e-02,  6.8763e-02, -5.7232e-02],\n",
      "          [-5.2957e-02,  1.8807e-02, -9.6698e-02, -7.0412e-02, -9.7253e-02],\n",
      "          [-3.1913e-02, -4.4936e-02,  8.3047e-02, -7.9049e-02,  3.3388e-02]],\n",
      "\n",
      "         [[-6.1374e-02,  1.6674e-02, -6.0471e-02, -1.7795e-02,  2.6388e-02],\n",
      "          [ 7.2846e-02,  7.7682e-02,  9.3021e-02,  9.8585e-03, -4.8674e-02],\n",
      "          [ 5.3929e-02, -3.6204e-02,  1.6232e-02, -1.8585e-02,  3.8121e-02],\n",
      "          [-9.3877e-02,  5.5940e-02, -6.5339e-02, -2.3546e-02,  5.0584e-02],\n",
      "          [-9.0773e-02,  2.8679e-02,  7.2362e-02, -1.7247e-03,  3.0972e-02]]]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0706, -0.0936, -0.0236, -0.0143], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[-4.4051e-02,  1.9427e-02,  5.1968e-02,  1.6281e-03, -3.8609e-02],\n",
      "          [ 6.5212e-03, -2.9544e-02,  3.1892e-03,  5.1879e-03,  7.0842e-02],\n",
      "          [-6.1455e-03, -2.2661e-02, -6.0312e-02, -5.5959e-02,  9.7910e-02],\n",
      "          [ 9.8117e-02, -2.5911e-02,  9.6801e-02,  7.0142e-02, -3.2137e-02],\n",
      "          [-8.9717e-02,  2.4156e-02, -2.4029e-02,  4.8768e-02,  2.5713e-02]],\n",
      "\n",
      "         [[ 7.1970e-03,  1.0106e-02,  2.4836e-02, -3.8244e-02, -6.0476e-02],\n",
      "          [ 6.6246e-02,  7.7227e-02, -6.9591e-02, -7.3570e-02, -8.2011e-02],\n",
      "          [-2.6955e-02, -5.1366e-02, -7.6738e-02, -4.0999e-02, -3.8929e-02],\n",
      "          [ 5.8491e-02, -6.3624e-02,  6.1567e-02,  5.8270e-02,  7.1889e-02],\n",
      "          [-2.3681e-02, -5.0408e-02,  5.7364e-02, -8.8368e-02, -5.5866e-02]],\n",
      "\n",
      "         [[-6.8758e-02,  1.8597e-02, -3.2442e-02, -7.6570e-02,  4.3303e-02],\n",
      "          [ 8.2451e-03,  2.9040e-02, -3.7991e-02, -8.7965e-05, -2.4041e-02],\n",
      "          [-7.2942e-02,  8.4554e-02, -2.1029e-02,  4.1491e-02,  1.8112e-02],\n",
      "          [ 1.4082e-02, -8.2408e-03, -6.2321e-02,  3.3990e-02, -2.0315e-02],\n",
      "          [-8.9687e-02, -1.1860e-02,  6.3468e-02, -3.8174e-02,  2.4888e-02]],\n",
      "\n",
      "         [[-4.1364e-02,  5.1155e-02, -8.8039e-03,  5.5044e-02,  4.7480e-02],\n",
      "          [ 8.8893e-02, -5.8860e-02, -6.9952e-03,  4.2118e-02,  3.0523e-02],\n",
      "          [ 4.9054e-02, -1.0141e-02, -6.4857e-02,  6.0592e-02, -3.7284e-02],\n",
      "          [ 3.9421e-02, -7.8650e-02, -7.1086e-02, -8.2836e-02,  4.9915e-02],\n",
      "          [-8.3333e-03, -4.1157e-03,  8.3226e-02,  9.2283e-02,  6.9968e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4751e-02, -1.1590e-02,  3.0355e-02, -1.1672e-02, -3.3619e-02],\n",
      "          [-9.2974e-02,  4.8178e-02,  1.1245e-02,  2.1455e-02,  5.5381e-02],\n",
      "          [ 8.8028e-02,  3.0392e-02,  8.5265e-02, -3.9108e-02,  6.0259e-03],\n",
      "          [-4.2593e-02,  8.1981e-02,  3.6712e-02, -1.6140e-02,  5.9932e-02],\n",
      "          [ 2.2551e-03, -8.9887e-03,  5.0076e-02,  6.0706e-03, -4.1579e-02]],\n",
      "\n",
      "         [[-7.9053e-02, -6.5703e-02,  6.4994e-02,  2.1459e-02,  5.4700e-02],\n",
      "          [-9.3977e-02, -5.6392e-02, -9.8745e-02, -6.0365e-02, -3.0354e-02],\n",
      "          [ 2.8447e-02,  1.1744e-03, -8.2208e-02,  9.1247e-02, -8.2728e-02],\n",
      "          [ 6.3636e-02,  6.0335e-02,  1.6675e-02,  5.8982e-02, -7.6166e-02],\n",
      "          [ 7.9119e-02, -9.1957e-02, -9.7391e-02, -1.2975e-03,  3.3856e-02]],\n",
      "\n",
      "         [[-2.8276e-02,  6.2225e-02, -5.7430e-02,  1.6585e-02,  3.0646e-02],\n",
      "          [ 3.5490e-02, -9.8069e-02,  1.4018e-02, -1.6322e-02,  7.4530e-02],\n",
      "          [-3.1131e-02, -9.1252e-02,  2.6808e-03,  1.3606e-02, -6.1697e-02],\n",
      "          [-3.5332e-02,  4.9098e-02, -8.6767e-02, -4.9013e-02, -9.5209e-03],\n",
      "          [-7.4204e-02, -2.3561e-02,  3.8097e-02,  3.6971e-02, -2.3882e-02]],\n",
      "\n",
      "         [[ 8.7051e-02,  2.3446e-02, -3.3814e-02,  8.9081e-02,  9.3541e-02],\n",
      "          [-3.0749e-02,  8.4861e-02,  3.6731e-02, -3.4109e-02,  2.1421e-02],\n",
      "          [-2.1340e-02,  9.2397e-03,  6.4926e-03, -1.0609e-02,  9.4451e-02],\n",
      "          [-1.9311e-02, -4.2329e-02, -7.5506e-02,  5.1623e-02, -8.5670e-02],\n",
      "          [-1.1214e-02, -4.0456e-02,  7.5436e-02, -9.0546e-02, -2.7859e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0617e-02,  3.0404e-02, -1.3135e-02,  6.3365e-02,  7.4431e-03],\n",
      "          [ 5.0839e-03,  3.6873e-02, -1.9596e-02, -7.8119e-02, -5.4665e-03],\n",
      "          [ 4.4530e-02, -6.4666e-02, -2.9636e-02, -5.8615e-02,  6.1582e-02],\n",
      "          [-1.7396e-02,  8.4934e-02,  4.2081e-02, -5.0777e-02, -8.4725e-02],\n",
      "          [-3.9153e-02,  5.9641e-02, -5.3340e-02, -6.2209e-03,  2.4746e-02]],\n",
      "\n",
      "         [[ 3.6020e-02, -3.5928e-02,  8.5019e-02,  6.0829e-02,  5.9144e-02],\n",
      "          [-4.0413e-02,  5.5318e-02,  3.4492e-02,  4.6455e-02, -3.8846e-02],\n",
      "          [ 5.3517e-02, -3.4646e-02, -7.8630e-02,  1.0226e-03, -4.8342e-02],\n",
      "          [ 6.9565e-02, -1.4681e-02, -2.5975e-03, -3.2394e-02,  2.2432e-02],\n",
      "          [ 8.5308e-02,  9.5422e-02, -6.7202e-02, -3.1421e-04, -8.2850e-02]],\n",
      "\n",
      "         [[ 7.1569e-02, -5.1188e-02,  7.5608e-03,  4.1318e-02,  9.1924e-02],\n",
      "          [ 2.3424e-02, -2.5898e-02, -3.3201e-02,  4.1777e-02, -2.4836e-02],\n",
      "          [ 9.1207e-02, -3.2147e-02,  2.8444e-02,  6.9077e-02, -9.1286e-02],\n",
      "          [ 9.4806e-02,  4.4660e-02,  8.7686e-02,  9.9127e-02,  3.7693e-02],\n",
      "          [-9.5433e-02,  3.1351e-02, -8.6033e-02, -1.1720e-03,  1.8451e-04]],\n",
      "\n",
      "         [[-3.6725e-02, -5.5309e-02,  6.9694e-02, -9.5555e-02, -9.9023e-02],\n",
      "          [ 3.2837e-02,  4.6232e-02,  9.8208e-02,  4.6720e-02, -6.6465e-02],\n",
      "          [ 5.5278e-02,  8.6134e-02,  3.4964e-02,  1.9327e-02, -7.0429e-02],\n",
      "          [-6.8981e-02,  3.8941e-02, -8.2875e-02,  4.2999e-05,  3.5569e-02],\n",
      "          [ 4.9634e-02,  7.1435e-02, -4.6407e-02, -4.2409e-02, -8.7845e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1276e-02,  8.0030e-02,  1.5093e-02,  3.9136e-02,  3.3604e-02],\n",
      "          [ 7.7356e-02,  6.1725e-02, -5.5334e-02, -3.8629e-02, -3.7572e-02],\n",
      "          [ 9.7396e-02,  2.6290e-02, -7.6834e-02,  7.4832e-02,  4.9578e-02],\n",
      "          [ 1.7733e-02,  3.8129e-02, -6.0733e-02,  8.1170e-03,  8.7473e-02],\n",
      "          [-9.4141e-02,  6.7758e-02,  1.0502e-02, -9.7039e-03,  8.0652e-02]],\n",
      "\n",
      "         [[ 2.4435e-02,  4.5891e-02, -9.1852e-02, -8.4367e-02, -5.7722e-02],\n",
      "          [ 6.7473e-02, -1.6719e-03, -3.0531e-02, -1.5898e-02, -5.4716e-02],\n",
      "          [ 4.9034e-03,  7.3446e-02,  7.0142e-02,  5.9416e-02, -8.8783e-02],\n",
      "          [-5.6294e-02,  4.9039e-03, -6.9839e-02,  7.2365e-02,  8.9130e-02],\n",
      "          [-8.1578e-02,  2.4236e-02,  6.0398e-02, -3.1360e-02, -8.3786e-02]],\n",
      "\n",
      "         [[ 7.3695e-02, -1.1377e-02, -8.1866e-02, -8.1100e-02,  2.6197e-02],\n",
      "          [-6.6974e-02,  8.1550e-02,  7.9556e-02, -2.1175e-02, -1.7586e-03],\n",
      "          [-8.3854e-02, -4.2315e-02, -5.3511e-02, -3.6663e-02, -6.9787e-03],\n",
      "          [-7.6059e-02, -1.1282e-02,  8.1843e-02,  7.2517e-02, -7.9277e-02],\n",
      "          [-1.5100e-02, -3.6461e-02, -3.3349e-02,  3.1808e-02,  1.5646e-02]],\n",
      "\n",
      "         [[ 2.6485e-02,  5.6684e-02,  4.2984e-02, -3.9332e-02, -8.0905e-02],\n",
      "          [ 2.3870e-02,  6.1497e-02,  6.6021e-02,  5.0583e-02,  3.4342e-02],\n",
      "          [-5.5407e-02, -1.9934e-02,  3.6921e-02,  2.3489e-02,  6.0573e-03],\n",
      "          [-3.4074e-02, -6.3634e-02, -5.3704e-02, -3.3664e-02, -8.7338e-02],\n",
      "          [-4.2829e-02,  5.1190e-02, -5.7242e-03,  8.4158e-02,  3.2569e-02]]]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0682,  0.0164,  0.0663, -0.0405], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[-4.6568e-02,  3.6973e-02,  6.7397e-03, -6.4272e-02,  8.0090e-02],\n",
      "          [-8.2242e-02, -7.6852e-02, -1.1350e-02,  5.5133e-02,  7.3789e-02],\n",
      "          [ 9.4985e-02,  6.6231e-04, -3.4953e-02,  3.0985e-02, -5.8245e-02],\n",
      "          [-8.5498e-02,  7.1367e-02,  2.0578e-02, -3.6039e-02,  5.7974e-02],\n",
      "          [-6.3452e-02, -1.9669e-02, -5.5945e-02,  9.5285e-02,  8.4938e-02]],\n",
      "\n",
      "         [[-9.1291e-02,  1.5787e-03, -4.0349e-02,  5.3323e-02,  3.2035e-02],\n",
      "          [ 5.5602e-02, -6.5424e-02,  7.6162e-02,  7.5876e-02,  7.5211e-02],\n",
      "          [-6.8722e-02, -5.2681e-02, -3.7479e-02, -3.9170e-02, -1.4258e-03],\n",
      "          [-5.9912e-02,  7.5041e-02,  7.6689e-02, -4.7997e-02,  3.6157e-02],\n",
      "          [ 6.6408e-02, -8.1891e-02,  9.7879e-02,  7.9299e-02,  9.6375e-02]],\n",
      "\n",
      "         [[-6.2165e-02, -2.1562e-03,  9.1708e-02, -3.7119e-02, -5.2456e-02],\n",
      "          [ 8.8863e-02,  8.5388e-02,  5.3866e-03, -5.3123e-02,  8.9410e-02],\n",
      "          [ 5.8967e-02,  8.4790e-02, -5.1751e-02, -1.8551e-02,  4.3811e-02],\n",
      "          [ 4.5143e-02,  7.8761e-02,  6.1901e-02,  4.9099e-02, -7.2353e-02],\n",
      "          [-2.5935e-02, -5.3747e-02,  1.8686e-02,  6.2788e-02,  3.3230e-02]],\n",
      "\n",
      "         [[-9.9926e-03,  7.8400e-02,  6.7855e-02,  5.5726e-02,  9.6075e-02],\n",
      "          [ 5.8463e-02, -8.1349e-02, -8.4812e-02,  6.8831e-02, -1.9880e-03],\n",
      "          [-6.6357e-02, -3.8544e-02,  9.6562e-02, -2.8835e-02, -3.2999e-03],\n",
      "          [ 8.2201e-02, -9.5534e-02, -7.2734e-02,  6.2241e-02,  6.1122e-02],\n",
      "          [ 2.8247e-02,  4.7865e-02,  5.0989e-02, -9.8759e-02,  1.2412e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7845e-02, -5.0020e-05,  2.0918e-02,  6.5073e-02, -7.6333e-03],\n",
      "          [-8.9775e-03, -7.8966e-03,  4.0687e-02, -9.4758e-02,  1.9336e-02],\n",
      "          [ 8.3771e-02,  8.5257e-02, -6.3525e-02,  7.9375e-02,  1.1055e-02],\n",
      "          [-8.1500e-02,  4.6795e-02, -6.4324e-03,  3.7890e-02,  5.9978e-02],\n",
      "          [-7.5366e-02, -2.1555e-02, -9.8922e-02, -2.1446e-02,  9.4078e-02]],\n",
      "\n",
      "         [[-9.1609e-02, -6.8573e-02, -2.1850e-02, -5.3172e-02,  9.3035e-02],\n",
      "          [ 6.1488e-02,  8.4657e-02, -4.0049e-02, -1.5989e-02,  1.8556e-02],\n",
      "          [ 9.6743e-02, -4.4434e-02, -5.8136e-02,  7.9239e-02, -7.3066e-02],\n",
      "          [ 5.0627e-02,  3.3798e-02, -9.4872e-02,  3.0070e-02, -8.1800e-03],\n",
      "          [-3.2585e-02,  2.5044e-02,  7.8404e-02, -2.0233e-02, -5.5182e-02]],\n",
      "\n",
      "         [[-4.3364e-02, -7.5323e-02, -7.1142e-02, -4.9581e-02, -8.0531e-02],\n",
      "          [ 3.8006e-02, -7.1328e-02, -8.5374e-02, -1.5537e-02,  4.5729e-02],\n",
      "          [ 5.3962e-02, -6.0527e-02, -6.1483e-02, -1.8816e-02,  2.7028e-02],\n",
      "          [ 4.9576e-02,  1.6251e-02, -4.4264e-02, -2.1607e-02,  7.6682e-02],\n",
      "          [-8.1483e-02,  2.5143e-02,  9.7919e-02,  2.2362e-02,  3.8527e-02]],\n",
      "\n",
      "         [[-2.2361e-03,  8.3025e-02, -5.6704e-02, -4.3653e-02,  5.2174e-03],\n",
      "          [-4.2206e-02,  1.5242e-02, -5.6023e-02, -7.0920e-02,  1.4973e-02],\n",
      "          [-8.6105e-02, -2.8613e-02, -6.6031e-02, -2.5562e-02, -8.2346e-02],\n",
      "          [-2.1652e-02, -5.3138e-02, -6.0070e-02, -8.6883e-02, -6.7856e-02],\n",
      "          [ 4.5293e-02,  8.7768e-02, -7.3287e-02,  8.1294e-02, -2.8931e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.7405e-02, -8.4552e-02,  9.9695e-02, -1.6831e-02,  4.8659e-02],\n",
      "          [-7.0148e-02, -8.8485e-02, -5.5307e-02,  1.5248e-02,  5.2276e-02],\n",
      "          [ 7.0753e-02,  2.7862e-02,  3.3296e-02, -1.6647e-02,  1.3415e-02],\n",
      "          [-9.1016e-03, -7.7574e-02, -4.7253e-02,  2.8168e-02, -7.9998e-02],\n",
      "          [ 7.3026e-02,  1.9647e-02,  3.5987e-03,  9.8112e-02, -3.9698e-02]],\n",
      "\n",
      "         [[ 4.0556e-02,  2.2181e-02,  1.8598e-02,  5.9261e-02, -5.6157e-02],\n",
      "          [ 2.1176e-02, -2.6344e-02,  1.5245e-02,  9.7703e-02,  1.4691e-02],\n",
      "          [ 6.5295e-02,  8.1575e-02, -9.2008e-02, -7.1621e-02, -6.7741e-02],\n",
      "          [ 9.0881e-03, -1.8137e-03,  7.6986e-02,  6.3903e-02, -9.4232e-02],\n",
      "          [ 6.2062e-03, -1.5664e-02, -4.0183e-02,  5.1219e-02, -7.9654e-02]],\n",
      "\n",
      "         [[ 3.1847e-02,  9.5598e-03, -3.6891e-02, -3.5388e-02,  8.1495e-02],\n",
      "          [ 3.2682e-02,  5.6163e-03, -7.5360e-02, -4.6031e-02,  1.5026e-02],\n",
      "          [ 6.9299e-02, -9.8742e-02,  7.9664e-02,  5.5446e-02, -9.7137e-02],\n",
      "          [ 6.0991e-02, -2.5863e-02,  4.4318e-02,  9.1188e-02, -6.8249e-02],\n",
      "          [-5.3161e-02, -6.5595e-02, -2.4030e-02, -6.7691e-02,  7.6572e-02]],\n",
      "\n",
      "         [[-5.8973e-02,  9.4267e-02,  9.4926e-02,  5.4102e-02,  7.7211e-02],\n",
      "          [ 1.4888e-02, -7.3853e-02,  5.8667e-02,  9.0196e-02, -6.2815e-02],\n",
      "          [ 9.4191e-02,  9.3694e-02, -5.5337e-02, -6.2685e-02, -1.9212e-03],\n",
      "          [ 6.0584e-02,  7.1926e-02,  7.9884e-02, -6.7902e-02,  7.8823e-02],\n",
      "          [ 2.1151e-02, -5.7482e-02,  8.7949e-02, -7.5958e-02,  4.3935e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0250e-02,  6.4416e-02, -7.5433e-03, -1.7187e-02, -1.1786e-02],\n",
      "          [ 7.0478e-02,  7.5330e-02, -9.6372e-03,  9.3548e-02, -9.4734e-02],\n",
      "          [ 2.9949e-02,  7.5121e-02, -9.7212e-02, -9.7945e-03, -5.2716e-02],\n",
      "          [ 4.2344e-02, -9.1881e-02,  4.1718e-02,  4.5746e-02,  5.5876e-02],\n",
      "          [-7.4455e-02,  9.1046e-02, -6.6931e-02, -5.7955e-02,  5.4433e-02]],\n",
      "\n",
      "         [[ 5.9614e-02, -1.5371e-03,  2.9684e-03, -5.6804e-02,  6.4716e-02],\n",
      "          [-7.1413e-02,  3.0440e-02, -6.1358e-04,  3.1095e-02,  3.3372e-02],\n",
      "          [ 9.7262e-02, -8.1119e-02,  4.4041e-02,  1.4918e-02,  8.2509e-02],\n",
      "          [-8.2262e-02,  2.6110e-02, -4.8939e-02, -1.7480e-02, -5.5513e-02],\n",
      "          [ 9.6112e-02,  1.8415e-02, -8.2241e-02, -6.9073e-02, -1.5276e-02]],\n",
      "\n",
      "         [[ 8.8620e-03, -7.9582e-02, -4.5482e-02,  2.5792e-02,  6.9616e-02],\n",
      "          [ 6.7280e-02,  4.8180e-02,  5.2162e-02,  4.6056e-02, -8.1786e-02],\n",
      "          [-8.3585e-02, -2.9809e-02,  4.3285e-02, -4.0554e-02, -8.8941e-02],\n",
      "          [-8.4019e-02,  6.1754e-02, -2.1119e-02,  1.4920e-02, -2.8335e-02],\n",
      "          [ 6.3083e-02, -2.3672e-02, -7.1686e-02, -6.7170e-02, -8.3959e-02]],\n",
      "\n",
      "         [[ 5.0127e-02, -9.2224e-02,  9.6951e-02, -6.6363e-02,  1.3150e-02],\n",
      "          [ 9.8749e-02, -5.7581e-02, -8.5636e-02,  4.3797e-02,  8.7821e-02],\n",
      "          [ 3.5553e-02,  6.9480e-02,  6.1871e-02, -3.8068e-02, -5.3989e-02],\n",
      "          [ 6.4438e-02, -1.8971e-02,  3.5457e-02, -1.3553e-02, -2.6489e-03],\n",
      "          [ 1.5837e-02, -9.1922e-02, -6.2305e-02,  8.4130e-02, -2.9332e-02]]]],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0478, -0.0371, -0.0406, -0.0541], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[-0.0520, -0.0980, -0.1455],\n",
      "          [-0.0615,  0.0987, -0.0491],\n",
      "          [-0.0804,  0.0613, -0.1074]],\n",
      "\n",
      "         [[-0.0391,  0.0560,  0.0120],\n",
      "          [ 0.1245,  0.1309, -0.0778],\n",
      "          [-0.0461, -0.0207,  0.0191]],\n",
      "\n",
      "         [[-0.1509, -0.1020, -0.0548],\n",
      "          [-0.0821, -0.1206, -0.0562],\n",
      "          [ 0.0887, -0.0737, -0.1096]],\n",
      "\n",
      "         [[-0.1538, -0.1631, -0.1122],\n",
      "          [ 0.0755,  0.0420,  0.1105],\n",
      "          [-0.1099, -0.0560,  0.0702]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1475,  0.1493,  0.1632],\n",
      "          [-0.0563, -0.0411,  0.0112],\n",
      "          [-0.0745,  0.1031, -0.0253]],\n",
      "\n",
      "         [[ 0.0453,  0.1132,  0.0536],\n",
      "          [-0.0628,  0.1299, -0.1570],\n",
      "          [-0.0583, -0.0281,  0.1069]],\n",
      "\n",
      "         [[-0.1453, -0.1006, -0.0423],\n",
      "          [-0.0181, -0.0705,  0.0245],\n",
      "          [-0.1570,  0.0373,  0.0279]],\n",
      "\n",
      "         [[ 0.0124, -0.0284,  0.0354],\n",
      "          [-0.1087,  0.1470, -0.0901],\n",
      "          [ 0.1308,  0.0984,  0.0554]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0224,  0.1366,  0.0699],\n",
      "          [-0.1269,  0.0123,  0.1504],\n",
      "          [ 0.0948, -0.0543,  0.0397]],\n",
      "\n",
      "         [[ 0.0320,  0.1226, -0.1546],\n",
      "          [-0.1665,  0.0121,  0.1183],\n",
      "          [-0.0734,  0.0397, -0.0573]],\n",
      "\n",
      "         [[ 0.0688, -0.0186,  0.0628],\n",
      "          [-0.0052,  0.1655, -0.1424],\n",
      "          [-0.1327,  0.1615, -0.1555]],\n",
      "\n",
      "         [[-0.0097,  0.0585, -0.0683],\n",
      "          [ 0.0012,  0.0754,  0.1187],\n",
      "          [-0.0659,  0.0858,  0.0136]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0838, -0.0401, -0.0509],\n",
      "          [ 0.1364, -0.0745,  0.0316],\n",
      "          [ 0.1001, -0.1219,  0.0554]],\n",
      "\n",
      "         [[-0.0804, -0.0519, -0.1130],\n",
      "          [ 0.1128, -0.0073,  0.1508],\n",
      "          [ 0.0602,  0.1176,  0.1492]],\n",
      "\n",
      "         [[-0.1304, -0.0816,  0.1478],\n",
      "          [ 0.0652, -0.0078, -0.0420],\n",
      "          [-0.0783, -0.0133,  0.1596]],\n",
      "\n",
      "         [[-0.0034,  0.1318, -0.0282],\n",
      "          [ 0.1310,  0.1429, -0.0978],\n",
      "          [-0.1516,  0.1382, -0.0180]]]], device='cuda:0')\n",
      "tensor([-0.1193, -0.0097,  0.0677,  0.0399], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0121,  0.0080, -0.0352,  ...,  0.0090,  0.0211,  0.0286],\n",
      "        [-0.0565, -0.0347, -0.0533,  ...,  0.0116,  0.0361,  0.0229],\n",
      "        [-0.0348,  0.0044,  0.0079,  ..., -0.0548,  0.0215, -0.0009],\n",
      "        ...,\n",
      "        [-0.0098, -0.0404, -0.0581,  ...,  0.0269, -0.0301, -0.0559],\n",
      "        [-0.0103, -0.0175,  0.0424,  ...,  0.0582, -0.0534, -0.0267],\n",
      "        [-0.0547,  0.0513, -0.0314,  ..., -0.0085,  0.0217,  0.0392]],\n",
      "       device='cuda:0')\n",
      "tensor([ 4.1970e-02,  9.0202e-03,  5.3032e-02,  4.1826e-02, -4.6916e-02,\n",
      "        -1.9413e-02,  1.0657e-02, -4.7123e-02, -2.1643e-02, -3.1226e-02,\n",
      "        -7.3495e-03,  4.8432e-02,  5.8608e-02, -3.2333e-03,  5.9364e-03,\n",
      "        -4.9755e-02,  1.5146e-02,  5.4507e-02,  5.4559e-02, -3.7071e-02,\n",
      "         1.0801e-02, -1.3441e-02,  5.2097e-02,  4.7543e-02,  1.8491e-02,\n",
      "        -5.9882e-02,  5.3412e-02,  2.3588e-02,  2.4856e-02,  4.5730e-02,\n",
      "         2.7711e-02, -1.3152e-02,  3.2699e-02, -2.5682e-04,  2.8087e-02,\n",
      "        -1.7377e-02,  5.2896e-02,  4.6270e-02, -4.4189e-02, -2.0247e-02,\n",
      "         6.0977e-02,  5.5584e-02, -5.3353e-02,  4.0628e-02, -5.0255e-02,\n",
      "         5.7363e-02, -3.3217e-02,  9.2454e-03,  5.7766e-03,  6.1912e-02,\n",
      "         2.4682e-02,  3.4788e-02,  3.7330e-03,  2.3953e-02, -2.4682e-02,\n",
      "        -3.4069e-02, -4.0742e-02,  4.6854e-02,  2.5951e-02,  5.8391e-02,\n",
      "         1.2319e-02,  2.3930e-03,  4.2730e-02,  5.8035e-03, -2.7526e-03,\n",
      "         4.9300e-02, -4.7438e-02,  3.3844e-02,  6.1772e-02, -3.5317e-02,\n",
      "        -2.8861e-02, -2.6200e-02,  2.1595e-02, -5.7909e-02, -3.1531e-02,\n",
      "        -3.2516e-05, -5.9040e-02, -5.0833e-02,  4.7677e-03,  1.1495e-02,\n",
      "         7.2902e-03, -1.2979e-02, -3.4446e-02, -4.9851e-02, -4.7060e-02,\n",
      "        -2.1018e-02, -4.1917e-02,  4.7587e-02, -4.5524e-02,  1.2312e-02,\n",
      "         1.7258e-02,  4.6068e-02,  1.3958e-02,  5.0751e-02, -3.2283e-02,\n",
      "         2.4504e-02,  2.0429e-02, -1.2338e-02, -2.0725e-02,  2.5712e-03],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.4369e-02, -2.8812e-02, -6.7207e-02,  4.0482e-03, -4.1776e-02,\n",
      "          7.1188e-02, -4.2781e-02,  9.9875e-03,  2.2986e-02, -5.2929e-02,\n",
      "         -6.8137e-02,  1.4239e-02, -7.5151e-02,  4.1228e-02, -6.6864e-02,\n",
      "          2.3721e-02, -6.3322e-02, -9.6598e-02,  1.5610e-02, -1.4529e-02,\n",
      "          5.4729e-02, -4.2354e-02,  5.2077e-02,  6.7807e-02, -2.8511e-02,\n",
      "          8.4604e-02, -3.7144e-02,  1.9815e-02,  8.9303e-02, -9.0500e-02,\n",
      "         -3.4121e-02,  2.5035e-02, -7.5514e-02,  4.5393e-02,  5.7157e-02,\n",
      "          7.3768e-02,  8.9287e-02,  2.2074e-03,  5.4529e-02, -1.3836e-02,\n",
      "         -1.6844e-02, -3.0474e-02,  3.3482e-02, -5.1813e-02,  7.1231e-03,\n",
      "          7.3255e-02, -4.8543e-03,  1.3105e-02, -6.3668e-02, -3.1099e-02,\n",
      "          4.4498e-02, -2.3824e-02,  5.7989e-02, -2.4107e-02,  2.1274e-02,\n",
      "         -5.2606e-03, -4.0170e-02,  9.4542e-03, -8.8448e-02,  1.9217e-02,\n",
      "         -4.9750e-02,  2.1666e-02, -7.2256e-02, -7.6700e-02, -4.3383e-02,\n",
      "          9.4801e-02,  3.6278e-02,  5.3002e-02,  1.8862e-02,  1.7511e-02,\n",
      "          5.5188e-02, -2.2786e-02, -7.7379e-05,  1.3076e-02,  8.1289e-02,\n",
      "         -2.6845e-02,  4.3698e-02,  1.1604e-03,  7.4739e-02, -4.8938e-02,\n",
      "         -2.8308e-02,  2.0726e-02,  5.5003e-02, -1.4433e-02, -8.5837e-02,\n",
      "         -3.6210e-02, -7.1010e-02,  6.7077e-02, -3.4792e-02, -4.8484e-02,\n",
      "         -1.1551e-04, -4.9866e-03, -9.5137e-02,  4.0091e-02, -6.0888e-02,\n",
      "          8.5564e-02, -3.5503e-02, -1.5434e-02, -8.7234e-03,  8.6789e-02],\n",
      "        [-3.3697e-02, -8.6652e-02,  8.3737e-02, -5.0785e-02, -8.2821e-02,\n",
      "          9.1823e-02, -6.6174e-02, -8.4404e-02, -4.0874e-02,  3.2935e-02,\n",
      "         -4.7633e-02, -9.5991e-02, -6.1029e-02, -8.9415e-02,  9.6506e-02,\n",
      "          7.0629e-02, -2.2612e-03,  8.4737e-02, -2.2301e-02, -7.7723e-02,\n",
      "         -7.7952e-02,  9.2797e-02, -3.6431e-02, -4.2528e-02, -6.1072e-02,\n",
      "         -6.0230e-02,  4.2145e-02, -6.9761e-02, -3.1095e-02,  5.7886e-02,\n",
      "          6.7445e-02,  4.9592e-03, -7.0047e-02,  6.3741e-02,  7.7423e-02,\n",
      "          2.1825e-02, -8.5800e-02, -3.4553e-02, -1.8913e-02,  5.9181e-02,\n",
      "          1.8568e-02, -7.9338e-03,  8.3610e-02, -4.2114e-02, -6.8624e-02,\n",
      "         -6.8244e-02, -9.3339e-02,  8.5835e-02,  8.9979e-02, -1.9014e-02,\n",
      "          4.4619e-02, -4.1895e-02, -7.2042e-02,  1.3120e-02,  2.0968e-02,\n",
      "         -7.0288e-02,  4.6700e-02, -6.3515e-02, -5.8154e-02,  8.3194e-02,\n",
      "          2.0422e-02, -9.3538e-02,  7.5335e-02,  3.6568e-02,  8.2880e-02,\n",
      "         -4.8980e-02, -3.7409e-02, -5.3820e-02,  8.7024e-02,  4.1792e-02,\n",
      "          2.9381e-02,  3.1702e-02,  3.4923e-02, -3.3885e-02, -6.9500e-02,\n",
      "         -1.6405e-02,  4.7817e-02, -7.2392e-02, -1.9957e-02,  5.1729e-02,\n",
      "          1.4485e-02, -7.2870e-02,  2.2828e-02, -2.2825e-02, -8.0269e-02,\n",
      "         -7.4037e-02, -6.8438e-02, -4.9183e-02, -9.1173e-02,  5.5759e-02,\n",
      "         -5.0324e-02,  9.5387e-02,  3.7544e-02,  8.8732e-02,  8.4354e-02,\n",
      "         -3.8147e-02,  6.5803e-02, -8.5331e-02,  5.3173e-03, -2.4290e-02],\n",
      "        [ 1.1996e-02, -2.9597e-02, -3.2004e-02,  6.6274e-02,  4.1427e-02,\n",
      "          8.7531e-02, -5.6720e-03,  2.3567e-02,  2.1809e-02,  5.3350e-02,\n",
      "         -6.4551e-02,  6.6725e-03, -7.6413e-02, -6.8391e-02,  4.8571e-02,\n",
      "          1.6716e-02, -5.4720e-02, -2.2888e-02,  8.0812e-02,  1.5873e-02,\n",
      "         -4.2302e-02, -7.8666e-02,  1.7307e-02, -3.2845e-02,  9.9811e-02,\n",
      "          5.9863e-02, -4.5714e-02, -8.2922e-02,  4.8283e-02, -1.6190e-02,\n",
      "         -1.4303e-02,  4.2950e-03, -4.4026e-02,  4.6745e-02,  2.5697e-02,\n",
      "         -6.7450e-02,  1.8676e-02, -2.7733e-03, -2.4852e-02,  1.5760e-02,\n",
      "         -7.5266e-02,  5.8892e-02, -3.4879e-02, -1.7569e-02,  5.4507e-02,\n",
      "          8.3530e-02,  6.6998e-02, -8.7679e-02,  2.6177e-02, -1.1492e-02,\n",
      "          3.5424e-02,  6.2804e-02, -7.0260e-02,  4.8471e-02,  4.3168e-02,\n",
      "          1.5643e-02, -1.2456e-02, -1.6135e-02, -6.4591e-02,  5.1106e-02,\n",
      "         -1.8432e-03,  6.1932e-02,  5.7685e-02,  1.9308e-02, -8.1700e-02,\n",
      "         -4.2409e-02,  9.5097e-02, -3.4927e-02, -4.1698e-02,  6.9197e-02,\n",
      "          2.0309e-02,  1.7891e-02,  3.6026e-02,  7.1061e-02, -8.7869e-02,\n",
      "          9.2085e-02,  5.2863e-02, -2.3787e-02,  3.2118e-02, -6.7071e-02,\n",
      "          9.1970e-02,  4.6746e-02, -1.4430e-02, -7.8809e-04,  9.8933e-02,\n",
      "          5.3239e-02,  6.5092e-02,  5.7188e-02,  1.8987e-02, -9.8468e-02,\n",
      "          9.3352e-02, -7.4483e-02, -5.2837e-02,  5.0056e-02,  3.4682e-02,\n",
      "         -1.8591e-02, -7.7946e-02,  5.7447e-02, -6.2669e-02,  6.2366e-03],\n",
      "        [ 5.3789e-02,  5.7769e-02, -2.6674e-03,  9.0133e-02, -9.1167e-02,\n",
      "         -3.2476e-03, -1.3508e-02,  3.2633e-02,  4.5324e-02,  5.0800e-02,\n",
      "          4.2156e-02,  2.7494e-02,  8.1777e-02,  9.6923e-02, -9.5329e-02,\n",
      "          4.4573e-02,  3.8707e-02, -6.7369e-02, -9.0154e-03, -1.6989e-02,\n",
      "          8.3663e-02, -7.7597e-02,  7.1322e-02, -7.0919e-02, -9.3723e-02,\n",
      "          2.0539e-02, -5.2179e-02,  6.6474e-02, -7.2003e-02,  1.5867e-02,\n",
      "         -9.9171e-02, -3.1269e-02,  2.4603e-02,  9.0647e-02, -2.3835e-02,\n",
      "          9.0325e-03, -3.0957e-02, -8.4240e-02,  7.8302e-02,  4.3080e-02,\n",
      "          1.7146e-02, -8.6169e-02,  5.8444e-02, -7.5535e-02, -5.5164e-02,\n",
      "         -2.5853e-02, -5.4898e-02, -5.4150e-02, -6.4500e-02, -9.8876e-02,\n",
      "         -7.7422e-02, -4.0911e-02, -9.7364e-02, -7.1650e-02, -7.9308e-02,\n",
      "         -3.0467e-02,  1.0334e-03, -9.1968e-02, -2.7164e-02,  4.4246e-02,\n",
      "          1.6321e-02, -3.6769e-02, -4.0629e-02,  7.7963e-02,  9.7349e-02,\n",
      "          1.0525e-02,  6.8295e-02,  5.8724e-02,  9.1595e-02, -1.5147e-02,\n",
      "          6.0843e-03,  6.1999e-03, -2.6373e-02,  5.2672e-02,  3.5971e-02,\n",
      "          7.3675e-02, -1.9594e-03,  9.9484e-02,  8.1491e-02,  3.0724e-02,\n",
      "         -2.1275e-02,  1.2107e-02,  3.2919e-02,  8.0104e-02,  1.0639e-02,\n",
      "          7.5691e-02, -1.2485e-02,  2.8840e-02,  7.8473e-02,  9.5011e-03,\n",
      "          2.1543e-02,  1.3797e-02, -5.9900e-02, -4.7621e-02,  6.8539e-02,\n",
      "          9.4704e-02, -4.3510e-02, -1.6498e-02,  5.9242e-02, -4.7912e-02],\n",
      "        [-8.2532e-02, -5.6547e-02,  7.9766e-02, -7.3647e-02,  4.9184e-02,\n",
      "         -4.0329e-03,  7.3438e-02, -6.8094e-02,  4.3557e-02,  5.4152e-02,\n",
      "         -3.8376e-02,  1.3476e-02,  3.7324e-02,  1.6149e-02,  1.9570e-02,\n",
      "          9.9069e-02, -4.0984e-02, -9.4349e-02,  5.6348e-03, -9.7301e-02,\n",
      "          7.3735e-02, -8.0086e-02,  2.7880e-02,  4.1191e-03,  3.6117e-02,\n",
      "         -7.6295e-02,  4.0532e-02,  8.7120e-02,  6.3407e-03,  5.4075e-02,\n",
      "          2.1331e-02,  3.1777e-02, -1.8630e-02,  1.3608e-02, -6.4528e-02,\n",
      "         -1.7418e-02,  1.9875e-02, -6.9630e-05, -9.3270e-02, -4.1966e-02,\n",
      "         -7.2959e-02,  6.0020e-02, -3.9002e-04, -4.1976e-02,  6.5423e-02,\n",
      "          3.8081e-02, -1.0640e-02,  4.3935e-02,  9.3508e-02,  8.0644e-02,\n",
      "         -8.2909e-02,  5.2301e-02, -9.2268e-02, -6.0217e-02, -3.0087e-02,\n",
      "          9.3771e-02,  3.1023e-02,  9.4981e-02, -7.3333e-02,  2.9591e-02,\n",
      "          4.9994e-02,  2.1604e-03, -9.5501e-02,  9.1520e-02, -1.1315e-02,\n",
      "         -9.4380e-02,  4.5867e-02,  6.5625e-02,  3.5606e-03, -4.8920e-03,\n",
      "         -8.3574e-02,  6.5227e-02,  2.7580e-02,  7.0109e-02, -5.1218e-02,\n",
      "          5.2946e-02, -5.5391e-02, -8.1037e-02,  9.4164e-03, -6.8240e-02,\n",
      "          5.8487e-02,  1.2619e-02,  7.5308e-02, -2.6155e-02, -5.8381e-02,\n",
      "          6.9487e-02,  1.7123e-02, -5.3776e-02, -5.6437e-02,  2.0755e-02,\n",
      "          4.8653e-02, -6.3464e-02, -5.9393e-02, -1.9278e-02,  8.1987e-03,\n",
      "         -7.3325e-02, -3.9076e-02,  7.5513e-02, -9.5494e-03, -4.7329e-02],\n",
      "        [ 7.9502e-02,  2.3833e-02, -5.5650e-02,  3.4456e-02, -3.8448e-02,\n",
      "          1.7272e-02, -1.1681e-02, -3.9949e-02, -3.0281e-02, -4.5553e-02,\n",
      "          3.7005e-02, -4.8572e-02, -1.0357e-02, -2.5574e-02,  9.0075e-02,\n",
      "          9.0610e-02, -5.8785e-02, -1.8193e-02, -8.0303e-02,  3.2311e-02,\n",
      "         -5.9347e-02,  4.3240e-02,  4.1584e-04,  7.1642e-02, -8.8371e-02,\n",
      "         -8.6058e-02, -9.9535e-02,  6.7250e-02,  4.9397e-02,  9.8117e-02,\n",
      "         -4.1241e-02, -4.5666e-02,  8.7484e-02, -5.8581e-02,  9.5534e-02,\n",
      "          9.5221e-02, -1.7595e-02, -8.7297e-02,  5.3337e-02, -9.1884e-02,\n",
      "         -8.8066e-02, -6.3223e-02,  9.8011e-03, -5.9041e-02,  6.2163e-02,\n",
      "          8.6801e-02, -2.3215e-03, -7.6899e-03, -1.8615e-03, -2.9277e-02,\n",
      "          4.9506e-02,  7.8865e-02,  8.8598e-02, -1.4848e-02,  3.8944e-02,\n",
      "         -1.9566e-02,  9.7433e-02, -6.3379e-02,  3.8374e-02,  8.4702e-03,\n",
      "          3.4781e-02,  3.3477e-02,  1.9872e-02, -9.3020e-03, -4.9728e-02,\n",
      "         -5.8416e-02,  5.6555e-04, -3.6826e-02, -6.6289e-02,  2.8031e-02,\n",
      "          5.7915e-02,  6.3258e-02,  2.3539e-02, -7.7230e-02,  5.5539e-02,\n",
      "          3.4264e-02, -9.6399e-02,  9.8610e-02,  9.2269e-02, -8.0045e-02,\n",
      "          9.7932e-02, -7.2935e-02,  9.4182e-02, -3.1073e-03,  4.3426e-02,\n",
      "          3.9058e-02,  8.2037e-02, -1.4291e-02,  9.0395e-02, -2.5516e-02,\n",
      "         -6.8257e-02,  7.4284e-02, -6.4864e-02, -4.1758e-02,  8.9759e-02,\n",
      "          2.7238e-02,  8.7467e-02, -2.4726e-02, -7.3298e-02, -6.6788e-02],\n",
      "        [-7.2314e-02, -4.7892e-02, -5.5441e-02, -3.9232e-03, -5.4490e-02,\n",
      "          1.5366e-02, -8.1141e-02,  7.4871e-02, -7.6999e-02, -5.3163e-02,\n",
      "          1.9351e-02,  8.2200e-02,  1.0321e-03, -4.8342e-02,  3.9597e-03,\n",
      "         -2.9546e-02, -9.1453e-02, -4.8979e-02, -7.9289e-02, -7.6676e-02,\n",
      "         -7.8974e-02,  7.5510e-03,  4.2900e-02, -8.5168e-02,  7.8944e-02,\n",
      "         -1.1572e-02,  4.7507e-02, -5.3402e-02,  1.2882e-02,  9.4094e-02,\n",
      "         -1.2953e-02, -9.9119e-02, -1.7842e-02,  9.4998e-05, -1.8350e-02,\n",
      "          2.8210e-02, -1.0434e-02, -4.5893e-02,  4.6050e-02, -3.1475e-02,\n",
      "         -5.3574e-02, -5.9010e-02,  5.6610e-02,  5.9642e-02, -5.9796e-02,\n",
      "         -3.3899e-02, -2.6252e-02,  8.8916e-02,  9.8842e-02,  5.6178e-02,\n",
      "         -5.0721e-02, -5.5737e-02,  2.1581e-02, -3.2865e-02, -8.1140e-02,\n",
      "          3.5804e-02,  2.6746e-02, -6.6694e-02,  6.7575e-02, -9.5642e-02,\n",
      "         -4.7690e-02,  8.3469e-02, -5.7036e-02,  5.6082e-02, -7.3411e-02,\n",
      "         -2.0372e-02, -2.1797e-02,  9.3842e-02,  4.9477e-03, -9.5448e-02,\n",
      "         -1.8307e-03,  5.7537e-02, -8.9228e-02,  4.6211e-02,  9.1961e-02,\n",
      "         -3.2000e-02, -4.8044e-02,  4.3631e-02, -8.0575e-02, -4.1399e-02,\n",
      "         -5.7628e-02,  5.1540e-02, -2.3669e-02, -6.1777e-02,  4.4018e-02,\n",
      "         -4.9475e-02, -2.7722e-02,  9.9552e-03, -8.6146e-02,  6.1715e-02,\n",
      "         -6.5720e-02,  1.6268e-02,  8.1976e-02,  9.3984e-02, -2.2669e-02,\n",
      "         -3.6762e-02, -2.8692e-02, -5.2823e-02, -4.4957e-02,  1.2675e-02],\n",
      "        [-8.8480e-02, -7.6116e-02, -5.9156e-02, -1.5243e-02,  9.8036e-02,\n",
      "         -7.3211e-02, -5.7227e-02,  2.7254e-02,  2.6892e-02,  9.3647e-02,\n",
      "          2.2033e-02,  3.0301e-02, -5.6205e-02, -6.7220e-02, -2.0605e-02,\n",
      "         -5.1808e-02,  5.4421e-03,  4.5141e-03, -4.3581e-02,  6.4007e-02,\n",
      "          3.1977e-03, -5.2794e-02, -1.6309e-02,  8.4588e-02, -6.8553e-02,\n",
      "         -9.9678e-02, -7.9407e-02,  4.1221e-02, -1.5030e-02,  4.4637e-02,\n",
      "          3.5418e-02,  7.2461e-02,  7.2928e-02, -6.4174e-02,  1.9854e-02,\n",
      "          5.6628e-02,  1.5674e-02, -2.9986e-02, -3.7490e-02,  5.8184e-02,\n",
      "          2.2648e-02, -6.2595e-02,  5.9513e-02,  4.9712e-02,  9.8886e-02,\n",
      "         -5.2540e-02, -5.5662e-02, -7.0133e-03, -6.8639e-02,  4.6026e-02,\n",
      "         -3.6715e-02,  9.3875e-02, -6.6822e-02, -8.5593e-02,  1.9258e-02,\n",
      "          8.1878e-02, -5.7737e-02, -1.7748e-02,  2.2771e-02, -4.4602e-02,\n",
      "         -5.5755e-04,  8.0585e-02, -9.3172e-02,  3.7835e-02, -8.1660e-03,\n",
      "         -6.1537e-03,  2.4425e-02, -4.2943e-02,  3.8899e-02, -6.5000e-02,\n",
      "         -6.8853e-02, -7.3400e-02, -3.4685e-02,  7.5617e-03,  7.0027e-02,\n",
      "         -7.4360e-02, -6.1868e-02,  7.5543e-02,  1.0629e-02, -6.2652e-02,\n",
      "          4.3030e-03,  7.9885e-02,  8.3717e-02,  5.7221e-02,  3.9837e-02,\n",
      "          2.7079e-02,  5.5853e-02, -4.5234e-02,  3.6132e-02, -8.5963e-02,\n",
      "          4.7007e-02,  5.7910e-02,  7.1492e-02, -2.2916e-02,  5.8064e-03,\n",
      "          2.0912e-02, -7.2909e-02, -3.6920e-02,  3.3646e-02,  7.6889e-02],\n",
      "        [-5.3568e-02, -7.9048e-02, -3.0465e-02,  1.8708e-02, -7.7081e-02,\n",
      "          2.8867e-03,  5.0510e-02, -8.5539e-02,  4.5372e-02, -4.7816e-02,\n",
      "         -8.7958e-02,  8.3956e-02, -9.5997e-02,  7.4101e-02, -3.1244e-02,\n",
      "          2.7328e-02,  2.9963e-02, -5.4199e-03, -5.9531e-02,  8.7839e-02,\n",
      "         -1.7094e-02, -8.6421e-02, -8.0091e-02,  8.6045e-02, -6.7006e-02,\n",
      "          6.1485e-02,  2.6375e-02,  1.9599e-03,  8.2396e-02,  5.3889e-02,\n",
      "         -5.2522e-02,  5.4195e-02,  1.4782e-05,  7.3130e-04,  8.7670e-02,\n",
      "          8.5434e-02, -8.7976e-02, -5.2475e-02, -1.6362e-02,  5.0729e-02,\n",
      "          1.5693e-02,  4.6524e-02,  2.5919e-02, -5.4068e-02,  3.0911e-02,\n",
      "          3.0081e-02,  1.4228e-02, -1.3467e-02, -8.4301e-02, -2.3248e-02,\n",
      "         -3.1672e-02,  8.9958e-02,  9.1513e-02,  6.6885e-02, -8.8425e-02,\n",
      "         -6.1266e-02,  3.1546e-03,  7.0914e-02, -4.1607e-02, -5.5327e-02,\n",
      "          4.6420e-02, -1.3156e-02, -4.1798e-02,  3.7031e-02, -4.8589e-02,\n",
      "         -1.7666e-02, -9.1633e-02,  8.6453e-02,  4.0117e-02,  7.3394e-02,\n",
      "          9.4643e-02,  5.6089e-02, -5.1844e-02,  3.4172e-02, -8.1946e-02,\n",
      "         -8.2052e-02,  1.0201e-02,  2.5796e-02,  8.0500e-02,  7.1805e-02,\n",
      "         -7.9501e-02,  1.9603e-02, -6.8380e-02, -7.4541e-02,  2.3806e-02,\n",
      "          1.5904e-03, -8.5528e-02,  1.7932e-02, -1.6448e-03,  2.2545e-02,\n",
      "         -7.1400e-02, -5.8614e-02,  2.3099e-02, -1.2095e-02, -5.5183e-02,\n",
      "          6.0113e-02, -1.9218e-02,  9.8615e-02, -5.4832e-02,  6.7391e-03],\n",
      "        [-3.4276e-02,  5.7128e-02,  7.4792e-02, -7.7430e-02, -5.3728e-02,\n",
      "          8.5178e-02,  9.8943e-02, -8.6549e-02,  5.6672e-02, -2.9597e-02,\n",
      "          4.3111e-02,  5.5099e-02,  1.1195e-02, -6.3908e-02, -7.5747e-02,\n",
      "         -2.7374e-04,  3.3018e-02,  9.4696e-02, -8.1805e-02,  7.4326e-02,\n",
      "         -3.0316e-02, -9.4801e-02, -8.3030e-03,  6.0986e-02, -8.0567e-02,\n",
      "          4.8060e-02, -4.8754e-02, -6.3612e-02,  9.3524e-02,  4.9238e-02,\n",
      "         -8.9937e-03, -4.1411e-02, -3.5429e-02, -8.1474e-02, -2.1521e-02,\n",
      "         -8.9077e-02, -8.5589e-02,  2.7094e-02,  6.8115e-02, -1.6380e-02,\n",
      "          6.5409e-03, -8.1511e-02,  1.1856e-02, -3.2090e-02,  3.3276e-02,\n",
      "          6.4681e-02, -8.1124e-02, -8.8595e-02, -9.2595e-02, -9.9023e-02,\n",
      "         -4.4443e-02, -2.2465e-02,  7.4431e-02, -6.2314e-02,  3.8228e-02,\n",
      "          6.5156e-02, -4.6550e-02,  3.4166e-02, -1.6976e-02, -9.2185e-02,\n",
      "         -2.7660e-02, -3.5915e-02,  2.9572e-02,  1.1122e-03,  6.3459e-02,\n",
      "         -6.2237e-02,  3.9288e-02, -3.0955e-02,  8.3621e-02,  8.4475e-02,\n",
      "         -2.1973e-02,  4.3513e-03, -4.3965e-02,  9.5753e-03,  4.8734e-02,\n",
      "         -7.6455e-02, -1.9122e-02, -1.0736e-02, -7.9074e-02, -6.9374e-02,\n",
      "         -8.1640e-02,  1.9667e-02, -7.9798e-02, -4.0288e-02, -4.1753e-02,\n",
      "          1.7417e-02,  9.3022e-02,  4.6815e-02, -5.8105e-02, -5.8528e-02,\n",
      "         -1.3946e-02,  7.3345e-02,  6.2373e-02, -3.3976e-03, -3.0443e-02,\n",
      "         -1.6620e-02,  4.6150e-02,  1.3030e-02, -3.0026e-02,  5.9118e-02]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0659, -0.0487,  0.0044,  0.0282,  0.0933, -0.0146, -0.0562, -0.0290,\n",
      "        -0.0177, -0.0847], device='cuda:0')\n",
      "tensor([[ 0.2960, -0.2903,  0.2163,  0.1676, -0.1456,  0.1199, -0.1824, -0.0060,\n",
      "         -0.0781, -0.2633]], device='cuda:0')\n",
      "tensor([-0.2445], device='cuda:0')\n",
      "total params: 27875\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for p in net.parameters():\n",
    "    n_params = np.prod(list(p.data.shape)).item()\n",
    "    count += n_params\n",
    "    print(p.data)\n",
    "print(f'total params: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.RMSprop(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On epoch: 0\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[292.6297]])\n",
      "Avg Abs Dev on dataset: tensor([[254.5506]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[286.0395]])\n",
      "Avg Abs Dev on dataset: tensor([[250.7449]])\n",
      "\n",
      "On epoch: 1\n",
      "\n",
      "On epoch: 2\n",
      "\n",
      "On epoch: 3\n",
      "\n",
      "On epoch: 4\n",
      "\n",
      "On epoch: 5\n",
      "\n",
      "On epoch: 6\n",
      "\n",
      "On epoch: 7\n",
      "\n",
      "On epoch: 8\n",
      "\n",
      "On epoch: 9\n",
      "\n",
      "On epoch: 10\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[243.8782]])\n",
      "Avg Abs Dev on dataset: tensor([[199.4862]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[221.2398]])\n",
      "Avg Abs Dev on dataset: tensor([[185.7750]])\n",
      "\n",
      "On epoch: 11\n",
      "\n",
      "On epoch: 12\n",
      "\n",
      "On epoch: 13\n",
      "\n",
      "On epoch: 14\n",
      "\n",
      "On epoch: 15\n",
      "\n",
      "On epoch: 16\n",
      "\n",
      "On epoch: 17\n",
      "\n",
      "On epoch: 18\n",
      "\n",
      "On epoch: 19\n",
      "\n",
      "On epoch: 20\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[126.3075]])\n",
      "Avg Abs Dev on dataset: tensor([[104.9573]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[117.7973]])\n",
      "Avg Abs Dev on dataset: tensor([[101.0599]])\n",
      "\n",
      "On epoch: 21\n",
      "\n",
      "On epoch: 22\n",
      "\n",
      "On epoch: 23\n",
      "\n",
      "On epoch: 24\n",
      "\n",
      "On epoch: 25\n",
      "\n",
      "On epoch: 26\n",
      "\n",
      "On epoch: 27\n",
      "\n",
      "On epoch: 28\n",
      "\n",
      "On epoch: 29\n",
      "\n",
      "On epoch: 30\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[51.0626]])\n",
      "Avg Abs Dev on dataset: tensor([[41.7011]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[41.2797]])\n",
      "Avg Abs Dev on dataset: tensor([[30.4700]])\n",
      "\n",
      "On epoch: 31\n",
      "\n",
      "On epoch: 32\n",
      "\n",
      "On epoch: 33\n",
      "\n",
      "On epoch: 34\n",
      "\n",
      "On epoch: 35\n",
      "\n",
      "On epoch: 36\n",
      "\n",
      "On epoch: 37\n",
      "\n",
      "On epoch: 38\n",
      "\n",
      "On epoch: 39\n",
      "\n",
      "On epoch: 40\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[28.3100]])\n",
      "Avg Abs Dev on dataset: tensor([[23.3064]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[25.6325]])\n",
      "Avg Abs Dev on dataset: tensor([[20.2280]])\n",
      "\n",
      "On epoch: 41\n",
      "\n",
      "On epoch: 42\n",
      "\n",
      "On epoch: 43\n",
      "\n",
      "On epoch: 44\n",
      "\n",
      "On epoch: 45\n",
      "\n",
      "On epoch: 46\n",
      "\n",
      "On epoch: 47\n",
      "\n",
      "On epoch: 48\n",
      "\n",
      "On epoch: 49\n",
      "\n",
      "On epoch: 50\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[45.9598]])\n",
      "Avg Abs Dev on dataset: tensor([[37.9981]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[45.7283]])\n",
      "Avg Abs Dev on dataset: tensor([[37.8499]])\n",
      "\n",
      "On epoch: 51\n",
      "\n",
      "On epoch: 52\n",
      "\n",
      "On epoch: 53\n",
      "\n",
      "On epoch: 54\n",
      "\n",
      "On epoch: 55\n",
      "\n",
      "On epoch: 56\n",
      "\n",
      "On epoch: 57\n",
      "\n",
      "On epoch: 58\n",
      "\n",
      "On epoch: 59\n",
      "\n",
      "On epoch: 60\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[37.7332]])\n",
      "Avg Abs Dev on dataset: tensor([[29.9620]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[36.8594]])\n",
      "Avg Abs Dev on dataset: tensor([[30.5399]])\n",
      "\n",
      "On epoch: 61\n",
      "\n",
      "On epoch: 62\n",
      "\n",
      "On epoch: 63\n",
      "\n",
      "On epoch: 64\n",
      "\n",
      "On epoch: 65\n",
      "\n",
      "On epoch: 66\n",
      "\n",
      "On epoch: 67\n",
      "\n",
      "On epoch: 68\n",
      "\n",
      "On epoch: 69\n",
      "\n",
      "On epoch: 70\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[55.5720]])\n",
      "Avg Abs Dev on dataset: tensor([[47.1755]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[50.7678]])\n",
      "Avg Abs Dev on dataset: tensor([[40.8172]])\n",
      "\n",
      "On epoch: 71\n",
      "\n",
      "On epoch: 72\n",
      "\n",
      "On epoch: 73\n",
      "\n",
      "On epoch: 74\n",
      "\n",
      "On epoch: 75\n",
      "\n",
      "On epoch: 76\n",
      "\n",
      "On epoch: 77\n",
      "\n",
      "On epoch: 78\n",
      "\n",
      "On epoch: 79\n",
      "\n",
      "On epoch: 80\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[87.5389]])\n",
      "Avg Abs Dev on dataset: tensor([[75.5670]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[85.2283]])\n",
      "Avg Abs Dev on dataset: tensor([[73.0401]])\n",
      "\n",
      "On epoch: 81\n",
      "\n",
      "On epoch: 82\n",
      "\n",
      "On epoch: 83\n",
      "\n",
      "On epoch: 84\n",
      "\n",
      "On epoch: 85\n",
      "\n",
      "On epoch: 86\n",
      "\n",
      "On epoch: 87\n",
      "\n",
      "On epoch: 88\n",
      "\n",
      "On epoch: 89\n",
      "\n",
      "On epoch: 90\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[54.2581]])\n",
      "Avg Abs Dev on dataset: tensor([[48.6104]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[52.6479]])\n",
      "Avg Abs Dev on dataset: tensor([[46.8064]])\n",
      "\n",
      "On epoch: 91\n",
      "\n",
      "On epoch: 92\n",
      "\n",
      "On epoch: 93\n",
      "\n",
      "On epoch: 94\n",
      "\n",
      "On epoch: 95\n",
      "\n",
      "On epoch: 96\n",
      "\n",
      "On epoch: 97\n",
      "\n",
      "On epoch: 98\n",
      "\n",
      "On epoch: 99\n",
      "\n",
      "On epoch: 100\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[28.7164]])\n",
      "Avg Abs Dev on dataset: tensor([[25.6707]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[28.5532]])\n",
      "Avg Abs Dev on dataset: tensor([[24.6275]])\n",
      "\n",
      "On epoch: 101\n",
      "\n",
      "On epoch: 102\n",
      "\n",
      "On epoch: 103\n",
      "\n",
      "On epoch: 104\n",
      "\n",
      "On epoch: 105\n",
      "\n",
      "On epoch: 106\n",
      "\n",
      "On epoch: 107\n",
      "\n",
      "On epoch: 108\n",
      "\n",
      "On epoch: 109\n",
      "\n",
      "On epoch: 110\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[132.4612]])\n",
      "Avg Abs Dev on dataset: tensor([[113.0588]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[132.0625]])\n",
      "Avg Abs Dev on dataset: tensor([[110.2898]])\n",
      "\n",
      "On epoch: 111\n",
      "\n",
      "On epoch: 112\n",
      "\n",
      "On epoch: 113\n",
      "\n",
      "On epoch: 114\n",
      "\n",
      "On epoch: 115\n",
      "\n",
      "On epoch: 116\n",
      "\n",
      "On epoch: 117\n",
      "\n",
      "On epoch: 118\n",
      "\n",
      "On epoch: 119\n",
      "\n",
      "On epoch: 120\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[30.6919]])\n",
      "Avg Abs Dev on dataset: tensor([[27.0771]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[29.7195]])\n",
      "Avg Abs Dev on dataset: tensor([[27.5104]])\n",
      "\n",
      "On epoch: 121\n",
      "\n",
      "On epoch: 122\n",
      "\n",
      "On epoch: 123\n",
      "\n",
      "On epoch: 124\n",
      "\n",
      "On epoch: 125\n",
      "\n",
      "On epoch: 126\n",
      "\n",
      "On epoch: 127\n",
      "\n",
      "On epoch: 128\n",
      "\n",
      "On epoch: 129\n",
      "\n",
      "On epoch: 130\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[37.0768]])\n",
      "Avg Abs Dev on dataset: tensor([[30.4649]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[38.1916]])\n",
      "Avg Abs Dev on dataset: tensor([[30.6416]])\n",
      "\n",
      "On epoch: 131\n",
      "\n",
      "On epoch: 132\n",
      "\n",
      "On epoch: 133\n",
      "\n",
      "On epoch: 134\n",
      "\n",
      "On epoch: 135\n",
      "\n",
      "On epoch: 136\n",
      "\n",
      "On epoch: 137\n",
      "\n",
      "On epoch: 138\n",
      "\n",
      "On epoch: 139\n",
      "\n",
      "On epoch: 140\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[26.6955]])\n",
      "Avg Abs Dev on dataset: tensor([[23.2887]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[23.7017]])\n",
      "Avg Abs Dev on dataset: tensor([[19.7434]])\n",
      "\n",
      "On epoch: 141\n",
      "\n",
      "On epoch: 142\n",
      "\n",
      "On epoch: 143\n",
      "\n",
      "On epoch: 144\n",
      "\n",
      "On epoch: 145\n",
      "\n",
      "On epoch: 146\n",
      "\n",
      "On epoch: 147\n",
      "\n",
      "On epoch: 148\n",
      "\n",
      "On epoch: 149\n",
      "\n",
      "On epoch: 150\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[41.0623]])\n",
      "Avg Abs Dev on dataset: tensor([[36.1186]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[39.0523]])\n",
      "Avg Abs Dev on dataset: tensor([[33.2709]])\n",
      "\n",
      "On epoch: 151\n",
      "\n",
      "On epoch: 152\n",
      "\n",
      "On epoch: 153\n",
      "\n",
      "On epoch: 154\n",
      "\n",
      "On epoch: 155\n",
      "\n",
      "On epoch: 156\n",
      "\n",
      "On epoch: 157\n",
      "\n",
      "On epoch: 158\n",
      "\n",
      "On epoch: 159\n",
      "\n",
      "On epoch: 160\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[25.9217]])\n",
      "Avg Abs Dev on dataset: tensor([[22.6605]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[27.5814]])\n",
      "Avg Abs Dev on dataset: tensor([[23.6157]])\n",
      "\n",
      "On epoch: 161\n",
      "\n",
      "On epoch: 162\n",
      "\n",
      "On epoch: 163\n",
      "\n",
      "On epoch: 164\n",
      "\n",
      "On epoch: 165\n",
      "\n",
      "On epoch: 166\n",
      "\n",
      "On epoch: 167\n",
      "\n",
      "On epoch: 168\n",
      "\n",
      "On epoch: 169\n",
      "\n",
      "On epoch: 170\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[34.2436]])\n",
      "Avg Abs Dev on dataset: tensor([[28.2407]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[36.5954]])\n",
      "Avg Abs Dev on dataset: tensor([[32.1730]])\n",
      "\n",
      "On epoch: 171\n",
      "\n",
      "On epoch: 172\n",
      "\n",
      "On epoch: 173\n",
      "\n",
      "On epoch: 174\n",
      "\n",
      "On epoch: 175\n",
      "\n",
      "On epoch: 176\n",
      "\n",
      "On epoch: 177\n",
      "\n",
      "On epoch: 178\n",
      "\n",
      "On epoch: 179\n",
      "\n",
      "On epoch: 180\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[98.8258]])\n",
      "Avg Abs Dev on dataset: tensor([[79.8768]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[101.0659]])\n",
      "Avg Abs Dev on dataset: tensor([[77.6586]])\n",
      "\n",
      "On epoch: 181\n",
      "\n",
      "On epoch: 182\n",
      "\n",
      "On epoch: 183\n",
      "\n",
      "On epoch: 184\n",
      "\n",
      "On epoch: 185\n",
      "\n",
      "On epoch: 186\n",
      "\n",
      "On epoch: 187\n",
      "\n",
      "On epoch: 188\n",
      "\n",
      "On epoch: 189\n",
      "\n",
      "On epoch: 190\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[64.8588]])\n",
      "Avg Abs Dev on dataset: tensor([[51.8794]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[64.2046]])\n",
      "Avg Abs Dev on dataset: tensor([[50.5747]])\n",
      "\n",
      "On epoch: 191\n",
      "\n",
      "On epoch: 192\n",
      "\n",
      "On epoch: 193\n",
      "\n",
      "On epoch: 194\n",
      "\n",
      "On epoch: 195\n",
      "\n",
      "On epoch: 196\n",
      "\n",
      "On epoch: 197\n",
      "\n",
      "On epoch: 198\n",
      "\n",
      "On epoch: 199\n",
      "\n",
      "On epoch: 200\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[38.9920]])\n",
      "Avg Abs Dev on dataset: tensor([[30.1818]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[41.3366]])\n",
      "Avg Abs Dev on dataset: tensor([[36.1859]])\n",
      "\n",
      "On epoch: 201\n",
      "\n",
      "On epoch: 202\n",
      "\n",
      "On epoch: 203\n",
      "\n",
      "On epoch: 204\n",
      "\n",
      "On epoch: 205\n",
      "\n",
      "On epoch: 206\n",
      "\n",
      "On epoch: 207\n",
      "\n",
      "On epoch: 208\n",
      "\n",
      "On epoch: 209\n",
      "\n",
      "On epoch: 210\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[56.0838]])\n",
      "Avg Abs Dev on dataset: tensor([[44.7744]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[54.3853]])\n",
      "Avg Abs Dev on dataset: tensor([[43.6418]])\n",
      "\n",
      "On epoch: 211\n",
      "\n",
      "On epoch: 212\n",
      "\n",
      "On epoch: 213\n",
      "\n",
      "On epoch: 214\n",
      "\n",
      "On epoch: 215\n",
      "\n",
      "On epoch: 216\n",
      "\n",
      "On epoch: 217\n",
      "\n",
      "On epoch: 218\n",
      "\n",
      "On epoch: 219\n",
      "\n",
      "On epoch: 220\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[100.6901]])\n",
      "Avg Abs Dev on dataset: tensor([[90.0246]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[100.5561]])\n",
      "Avg Abs Dev on dataset: tensor([[89.0052]])\n",
      "\n",
      "On epoch: 221\n",
      "\n",
      "On epoch: 222\n",
      "\n",
      "On epoch: 223\n",
      "\n",
      "On epoch: 224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On epoch: 225\n",
      "\n",
      "On epoch: 226\n",
      "\n",
      "On epoch: 227\n",
      "\n",
      "On epoch: 228\n",
      "\n",
      "On epoch: 229\n",
      "\n",
      "On epoch: 230\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[35.9609]])\n",
      "Avg Abs Dev on dataset: tensor([[32.2699]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[33.7302]])\n",
      "Avg Abs Dev on dataset: tensor([[29.3638]])\n",
      "\n",
      "On epoch: 231\n",
      "\n",
      "On epoch: 232\n",
      "\n",
      "On epoch: 233\n",
      "\n",
      "On epoch: 234\n",
      "\n",
      "On epoch: 235\n",
      "\n",
      "On epoch: 236\n",
      "\n",
      "On epoch: 237\n",
      "\n",
      "On epoch: 238\n",
      "\n",
      "On epoch: 239\n",
      "\n",
      "On epoch: 240\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[39.6926]])\n",
      "Avg Abs Dev on dataset: tensor([[29.4960]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[39.5574]])\n",
      "Avg Abs Dev on dataset: tensor([[30.2091]])\n",
      "\n",
      "On epoch: 241\n",
      "\n",
      "On epoch: 242\n",
      "\n",
      "On epoch: 243\n",
      "\n",
      "On epoch: 244\n",
      "\n",
      "On epoch: 245\n",
      "\n",
      "On epoch: 246\n",
      "\n",
      "On epoch: 247\n",
      "\n",
      "On epoch: 248\n",
      "\n",
      "On epoch: 249\n",
      "\n",
      "On epoch: 250\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[31.7675]])\n",
      "Avg Abs Dev on dataset: tensor([[27.7269]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[34.6401]])\n",
      "Avg Abs Dev on dataset: tensor([[31.0300]])\n",
      "\n",
      "On epoch: 251\n",
      "\n",
      "On epoch: 252\n",
      "\n",
      "On epoch: 253\n",
      "\n",
      "On epoch: 254\n",
      "\n",
      "On epoch: 255\n",
      "\n",
      "On epoch: 256\n",
      "\n",
      "On epoch: 257\n",
      "\n",
      "On epoch: 258\n",
      "\n",
      "On epoch: 259\n",
      "\n",
      "On epoch: 260\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[41.3708]])\n",
      "Avg Abs Dev on dataset: tensor([[35.3125]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[41.0075]])\n",
      "Avg Abs Dev on dataset: tensor([[33.6159]])\n",
      "\n",
      "On epoch: 261\n",
      "\n",
      "On epoch: 262\n",
      "\n",
      "On epoch: 263\n",
      "\n",
      "On epoch: 264\n",
      "\n",
      "On epoch: 265\n",
      "\n",
      "On epoch: 266\n",
      "\n",
      "On epoch: 267\n",
      "\n",
      "On epoch: 268\n",
      "\n",
      "On epoch: 269\n",
      "\n",
      "On epoch: 270\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[21.9635]])\n",
      "Avg Abs Dev on dataset: tensor([[19.5939]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[22.6036]])\n",
      "Avg Abs Dev on dataset: tensor([[19.4147]])\n",
      "\n",
      "On epoch: 271\n",
      "\n",
      "On epoch: 272\n",
      "\n",
      "On epoch: 273\n",
      "\n",
      "On epoch: 274\n",
      "\n",
      "On epoch: 275\n",
      "\n",
      "On epoch: 276\n",
      "\n",
      "On epoch: 277\n",
      "\n",
      "On epoch: 278\n",
      "\n",
      "On epoch: 279\n",
      "\n",
      "On epoch: 280\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[54.8528]])\n",
      "Avg Abs Dev on dataset: tensor([[47.0883]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[57.2241]])\n",
      "Avg Abs Dev on dataset: tensor([[48.5901]])\n",
      "\n",
      "On epoch: 281\n",
      "\n",
      "On epoch: 282\n",
      "\n",
      "On epoch: 283\n",
      "\n",
      "On epoch: 284\n",
      "\n",
      "On epoch: 285\n",
      "\n",
      "On epoch: 286\n",
      "\n",
      "On epoch: 287\n",
      "\n",
      "On epoch: 288\n",
      "\n",
      "On epoch: 289\n",
      "\n",
      "On epoch: 290\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[31.4265]])\n",
      "Avg Abs Dev on dataset: tensor([[27.8420]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[32.5427]])\n",
      "Avg Abs Dev on dataset: tensor([[29.6870]])\n",
      "\n",
      "On epoch: 291\n",
      "\n",
      "On epoch: 292\n",
      "\n",
      "On epoch: 293\n",
      "\n",
      "On epoch: 294\n",
      "\n",
      "On epoch: 295\n",
      "\n",
      "On epoch: 296\n",
      "\n",
      "On epoch: 297\n",
      "\n",
      "On epoch: 298\n",
      "\n",
      "On epoch: 299\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor([[34.9959]])\n",
      "Avg Abs Dev on dataset: tensor([[30.1083]])\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor([[37.3590]])\n",
      "Avg Abs Dev on dataset: tensor([[31.7942]])\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# For early stopping, use blocks of epochs (say size 3), and a window (say size 10) of how far to look in the past.\n",
    "# Then, compare the average loss on the current block to the block in the past. Another idea would be compare the variances.\n",
    "# If the fraction is not sufficiently small, halt.\n",
    "\n",
    "batch_multiplier = 20\n",
    "\n",
    "max_epochs = 300\n",
    "# Should be stated as a fraction of the previous error\n",
    "max_frac = 0.999\n",
    "window = 10 # How many epochs in the past to compare to\n",
    "block = 5 # What size block of epochs to use\n",
    "learnFreq = 10 # How often to compute evaluation loss (on training and validation sets)\n",
    "\n",
    "epoch_training_loss = []\n",
    "epoch_val_loss = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"\\nOn epoch: \" + str(epoch))\n",
    "    \n",
    "    #running_loss = 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    net.train()\n",
    "    for inputs, labels in training_generator:\n",
    "        \n",
    "        inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "        \n",
    "        if count == 0:\n",
    "            optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            count = batch_multiplier\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).to(device)\n",
    "        loss = criterion(torch.squeeze(outputs), labels) / batch_multiplier\n",
    "        loss.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        count -=1\n",
    "        \n",
    "        loss = loss.detach()\n",
    "        inputs = inputs.detach()\n",
    "        outputs = outputs.detach()\n",
    "        \n",
    "        #print('Outputs', torch.squeeze(outputs))\n",
    "        #print('Batch size: ' + str(len(inputs)))\n",
    "        # Multiply by the batch size and batch_multiplier (because earlier divided)\n",
    "        #running_loss += loss.item() * len(inputs) * batch_multiplier\n",
    "        #print('Batch average loss ' + str(loss.item()))\n",
    "    #training_loss = running_loss / training_set.__len__()\n",
    "    #print(\"Epoch training loss: \" + str(training_loss))\n",
    "    #epoch_training_loss.append(training_loss)\n",
    "    if epoch % learnFreq == 0 or epoch == (max_epochs - 1):\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for i, dataset in enumerate([training_set, validation_set]):\n",
    "                if i == 0:\n",
    "                    print('\\nEpoch training results ')\n",
    "                else:\n",
    "                    print('\\nEpoch validation results ')\n",
    "                MSE = 0\n",
    "                avgAbsDev = 0\n",
    "                for sample in dataset.ids:\n",
    "                    X, y = dataset.__getitem__(sample)\n",
    "                    X = X.unsqueeze(0) # Add fake batch dimension\n",
    "                    X = X.to(device).float()\n",
    "        \n",
    "                    yHat = net(X).to(device).to('cpu')\n",
    "                    MSE += (yHat - y)**2\n",
    "                    avgAbsDev += np.abs(yHat - y)\n",
    "        \n",
    "                #print('Sample: ' + str(sample))\n",
    "                #print('y: ' + str(y))\n",
    "                #print('yHat: ' + str(yHat))\n",
    "                MSE /= len(dataset.ids)\n",
    "                avgAbsDev /= len(dataset.ids)\n",
    "                print('RMSE on dataset: ' + str(np.sqrt(MSE)))\n",
    "                print('Avg Abs Dev on dataset: ' + str(avgAbsDev))\n",
    "                if i == 0:\n",
    "                    epoch_training_loss.append(MSE)\n",
    "                else:\n",
    "                    epoch_val_loss.append(MSE)\n",
    "        \n",
    "#         val_loss = 0\n",
    "#         net.eval()\n",
    "#         for ind in validation_set.ids:\n",
    "#             X, y = validation_set.__getitem__(ind)\n",
    "#             X = X.unsqueeze(0).to(device) # Add fake batch dimension\n",
    "#             yHat = net(X.float()).to(device).to('cpu')\n",
    "#             val_loss += (y - yHat)**2\n",
    "#         val_loss /= validation_set.__len__()\n",
    "#         epoch_val_loss.append(val_loss)\n",
    "#     print(\"Epoch validation loss: \" + str(val_loss))\n",
    "        \n",
    "#     if len(epoch_val_loss) >= window + block + 1:\n",
    "#         latestBlock = np.mean(epoch_val_loss[-1:-1-block])\n",
    "#         earlierBlock = np.mean(epoch_val_loss[-1-window:-1-window-block])\n",
    "        \n",
    "#         # latestBlock must be sufficiently smaller than earlierBlock\n",
    "#         if latestBlock / earlierBlock > max_frac:\n",
    "#             print('Converged')\n",
    "#             pdb.set_trace()\n",
    "#             break\n",
    "             \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training results \n",
      "RMSE on dataset: tensor([[34.9959]])\n",
      "Avg Abs Dev on dataset: tensor([[30.1083]])\n",
      "\n",
      "Validation results \n",
      "RMSE on dataset: tensor([[37.3590]])\n",
      "Avg Abs Dev on dataset: tensor([[31.7942]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i, dataset in enumerate([training_set, validation_set]):\n",
    "        if i == 0:\n",
    "            print('\\nTraining results ')\n",
    "        else:\n",
    "            print('\\nValidation results ')\n",
    "        MSE = 0\n",
    "        avgAbsDev = 0\n",
    "        for sample in dataset.ids:\n",
    "            X, y = dataset.__getitem__(sample)\n",
    "            X = X.unsqueeze(0) # Add fake batch dimension\n",
    "            X = X.to(device).float()\n",
    "\n",
    "            yHat = net(X).to(device).to('cpu')\n",
    "            MSE += (yHat - y)**2\n",
    "            avgAbsDev += np.abs(yHat - y)\n",
    "\n",
    "        #print('Sample: ' + str(sample))\n",
    "        #print('y: ' + str(y))\n",
    "        #print('yHat: ' + str(yHat))\n",
    "        MSE /= len(dataset.ids)\n",
    "        avgAbsDev /= len(dataset.ids)\n",
    "        print('RMSE on dataset: ' + str(np.sqrt(MSE)))\n",
    "        print('Avg Abs Dev on dataset: ' + str(avgAbsDev))\n",
    "        \n",
    "# with torch.no_grad():\n",
    "#     net.eval()\n",
    "#     for i, dataset in enumerate([training_set, validation_set, test_set]):\n",
    "#         if i == 0:\n",
    "#             print('\\nTraining Set Results')\n",
    "#         elif i == 1:\n",
    "#             print('\\nValidation Set Results')\n",
    "#         else:\n",
    "#             print('\\nTest set Results')\n",
    "#         MSE = 0\n",
    "#         avgAbsDev = 0\n",
    "#         for sample in dataset.ids:\n",
    "#             X, y = dataset.__getitem__(sample)\n",
    "#             X = X.unsqueeze(0) # Add fake batch dimension\n",
    "#             X = X.to(device).float()\n",
    "        \n",
    "#             yHat = net(X).to(device).to('cpu')\n",
    "#             MSE += (yHat - y)**2\n",
    "#             avgAbsDev += np.abs(yHat - y)\n",
    "        \n",
    "#             #print('Sample: ' + str(sample))\n",
    "#             #print('y: ' + str(y))\n",
    "#             #print('yHat: ' + str(yHat))\n",
    "#         MSE /= len(dataset.ids)\n",
    "#         avgAbsDev /= len(dataset.ids)\n",
    "#         print('RMSE on dataset: ' + str(np.sqrt(MSE)))\n",
    "#         print('Avg Abs Dev on dataset: ' + str(avgAbsDev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f4dc41331c0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc4133190>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc4157f40>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fbc340>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fbc850>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fb4850>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fbccd0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc1220>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc1730>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc1c70>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc61c0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc66d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc6be0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fcd130>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc6940>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc19a0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fbcb80>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fcd820>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fcdd30>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f54280>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f54790>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f54ca0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f591f0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f59700>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f54820>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fcd970>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3fc68b0>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f59c10>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f61160>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f61670>,\n",
       "  <matplotlib.axis.XTick at 0x7f4dc3f61b80>],\n",
       " <a list of 31 Text major ticklabel objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "ax = plt.figure()\n",
    "plt.plot(range(0, max_epochs + learnFreq, learnFreq), epoch_training_loss, range(0, max_epochs + learnFreq, learnFreq), epoch_val_loss)\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.xticks(range(0,max_epochs+10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570999808"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2490945536"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1505755136"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3214934016"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
