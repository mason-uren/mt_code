{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def get_random_crop(image, crop_height, crop_width):\n",
    "\n",
    "    max_x = image.shape[1] - crop_width\n",
    "    max_y = image.shape[0] - crop_height\n",
    "\n",
    "    x = np.random.randint(0, max_x)\n",
    "    y = np.random.randint(0, max_y)\n",
    "\n",
    "    crop = image[y: y + crop_height, x: x + crop_width]\n",
    "\n",
    "    return crop, x, y\n",
    "\n",
    "def searchForFocus(filename, substring):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read()\n",
    "        location = data.find(substring)\n",
    "        croppedStr = data[location+len(substring):]\n",
    "        # Split at spaces and find first number\n",
    "        for word in croppedStr.split(): # Split at spaces\n",
    "            # Delete any commas    \n",
    "            word = word.replace(',', \"\")\n",
    "            try:\n",
    "                focusPosition = int(word)\n",
    "                return focusPosition\n",
    "            except ValueError:\n",
    "                continue\n",
    "    file.close()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    # ids indicates what subfolders (samples) to access\n",
    "    def __init__(self, foldername, subfolderPrefix, ids):\n",
    "        self.foldername = foldername\n",
    "        self.subfolderPrefix = subfolderPrefix\n",
    "        self.ids = ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sampleFoldername = self.foldername + '/' + self.subfolderPrefix + str(index)\n",
    "        \n",
    "        # H, W\n",
    "        cropSize = (640, 640)\n",
    "        \n",
    "        images = []\n",
    "        for i, prefix in enumerate(['before', 'after']):\n",
    "        \n",
    "            # Load in image as [0,1] array\n",
    "            image = cv2.imread(sampleFoldername + '/' + prefix + str(index) + '.tif', 0) * 1 / 255.0\n",
    "\n",
    "            # Shift it so is from [-1,1]\n",
    "            image *= 2\n",
    "            image -= 1\n",
    "            \n",
    "            if i == 0:\n",
    "                # Randomly crop the image\n",
    "                image, cornerX, cornerY = get_random_crop(image, cropSize[0], cropSize[1])\n",
    "            else:\n",
    "                # Crop the label image to the same region as the input\n",
    "                image = image[cornerY:cornerY + cropSize[0], cornerX:cornerX + cropSize[1]]\n",
    "            \n",
    "            temp = torch.from_numpy(image)\n",
    "            if i == 0:\n",
    "                temp = temp.unsqueeze(0) # Add fake first dimension to specify 1-channel\n",
    "            images.append(temp)\n",
    "            \n",
    "        return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "params = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}\n",
    "\n",
    "# Randomly partition the full list into a training set and validation set\n",
    "numSamples = 100 # total number of samples collected\n",
    "frac = 1/5 # fraction to be validation\n",
    "np.random.seed(0)\n",
    "permutedIds = np.random.permutation(range(numSamples))\n",
    "splitPoint = int((1-frac) * len(permutedIds))\n",
    "trainingIds = permutedIds[:splitPoint]\n",
    "valIds = permutedIds[splitPoint:]\n",
    "\n",
    "training_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', trainingIds)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', valIds)\n",
    "#validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = training_set.__getitem__(1)\n",
    "\n",
    "def imshow(img,wait):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = np.squeeze(img.numpy())\n",
    "    width = int(0.15 * npimg.shape[1])\n",
    "    height = int(0.15 * npimg.shape[0])\n",
    "    cv2.imshow(\"Hi\",cv2.resize(npimg, (width, height)))\n",
    "    cv2.waitKey(wait)\n",
    "    cv2.destroyAllWindows()\n",
    "imshow(X, 10000)\n",
    "print(X.shape)\n",
    "imshow(Y, 10000)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider placing dropout layers after conv2d layers (conv2d -> batchnorm2d -> leakyReLU -> dropout(p=0.1))\n",
    "# And also place after fully connected layers (linear -> leakyReLU -> dropout(p=0.3))\n",
    "# TODO: Should actually figure out appropriate amount of padding for layers \n",
    "\n",
    "net = nn.Sequential(\n",
    "    # Encoder section\n",
    "    \n",
    "    # Does not change channel dimensions\n",
    "    nn.Conv2d(1, 4, kernel_size=9, stride=1, padding=4),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    # 1/4 channel dimensions\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    # Does not change channel dimensions\n",
    "    nn.Conv2d(4, 4, kernel_size=7, stride=1, padding=3),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    # 1/4 channel dimensions\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # Does not change channel dimensions\n",
    "    nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    # 1/4 channel dimensions\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    # At this point:\n",
    "    # Each channel has dimensions\n",
    "    # H_out, W_out = (1/4)^3 * (H_in, W_in)\n",
    "    \n",
    "    # Decoder section\n",
    "    nn.ConvTranspose2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "    \n",
    "    nn.ConvTranspose2d(4, 4, kernel_size=7, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "    \n",
    "    nn.ConvTranspose2d(4, 4, kernel_size=9, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Upsample(scale_factor = 2, mode='bilinear'),\n",
    "    \n",
    "#     nn.ConvTranspose2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "#     nn.BatchNorm2d(4),\n",
    "#     nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "#     nn.Upsample(scale_factor = (2, 2)),\n",
    "    \n",
    "    nn.ConvTranspose2d(4, 1, kernel_size=3, stride=1, padding=1),\n",
    "    nn.Tanh(),\n",
    ")\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dimIn, dimOut, kernel, leakySlope, poolSize, use_norm):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        block = [nn.Conv2d(dimIn, dimOut, kernel_size=kernel, stride=1, padding= (kernel-1) // 2)]\n",
    "        \n",
    "        if use_norm:\n",
    "            block += [nn.BatchNorm2d(dimOut)]\n",
    "        block += [nn.LeakyReLU(negative_slope = leakySlope, inplace=True),\n",
    "                  nn.MaxPool2d(kernel_size=poolSize, stride=poolSize)]\n",
    "        \n",
    "        self.block = nn.Sequential(*block)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dimIn, dimOut, kernel, leakySlope, scale, use_norm):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        block = [nn.ConvTranspose2d(dimIn, dimOut, kernel_size=kernel, stride=1, padding= (kernel-1) // 2)]\n",
    "        \n",
    "        if use_norm:\n",
    "            block += [nn.BatchNorm2d(dimOut)]\n",
    "        block += [nn.LeakyReLU(negative_slope = leakySlope, inplace=True),\n",
    "                  nn.Upsample(scale_factor = scale, mode = 'bilinear')]\n",
    "        \n",
    "        self.block = nn.Sequential(*block)\n",
    "            \n",
    "    def forward(self, x, earlierX = None):\n",
    "        #print('Called Decoder forward')\n",
    "        if earlierX is not None:\n",
    "            #print('Shape of x: ', x.size())\n",
    "            #print('Shape of earlierX: ', earlierX.size())\n",
    "            combinedChannels = torch.cat([x, earlierX], 1)\n",
    "            #print('Shape of combinedChannels: ', combinedChannels.size())\n",
    "            return self.block(combinedChannels)\n",
    "        else:\n",
    "            return self.block(x)\n",
    "        \n",
    "class EndBlock(nn.Module):\n",
    "    def __init__(self, dimIn, kernel):\n",
    "        super(EndBlock, self).__init__()\n",
    "        \n",
    "        self.block = \\\n",
    "        nn.Sequential(nn.ConvTranspose2d(dimIn, 1, kernel_size=kernel, padding= (kernel-1) // 2), nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, numEncoder, numDecoder):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        layers = [('e0', EncoderBlock(1, 16, 9, 0.1, 4, True))]\n",
    "        #self.layers = [EncoderBlock(1, 4, 5, 0.1, 4, True, 'e0')]\n",
    "\n",
    "        for i in range(1, numEncoder):\n",
    "            layers += [('e' + str(i), EncoderBlock(16, 16, 7, 0.1, 4, True))]\n",
    "            #self.layers += [EncoderBlock(4, 4, 5, 0.1, 4, True, 'e' + str(i))]\n",
    "\n",
    "        for j in range(numDecoder):\n",
    "            added = 1\n",
    "            layers += [('d' + str(j), DecoderBlock(16 + added, 16, 7, 0.1, 4, True))]\n",
    "            #self.layers += [DecoderBlock(4 + added, 4, 5, 0.1, 4, True, 'd' + str(j))]\n",
    "\n",
    "        #layers += [('f', nn.ConvTranspose2d(4, 1, kernel_size=5, padding=2), nn.Tanh())]\n",
    "        layers += [('f', EndBlock(16, 5))]\n",
    "        \n",
    "        #self.layers += [nn.ConvTranspose2d(4, 1, kernel_size=5, padding=2), nn.Tanh()]\n",
    "\n",
    "        print('layers', layers)\n",
    "        self.model = nn.Sequential(*[layers[i][1] for i in range(len(layers))])\n",
    "        \n",
    "        self.numEncoder = numEncoder\n",
    "        self.numDecoder = numDecoder\n",
    "        self.layers = layers\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # print('Calling forward')\n",
    "        layerOutputs = {}\n",
    "        prevVal = x.clone()\n",
    "        for (name, group) in self.layers:\n",
    "            #print('On layer: ' + block[0])\n",
    "            if name[0] == 'd':\n",
    "                # TODO: Finish this!\n",
    "                # Pass in a randomly cropped portion of the image that aligns with the current size\n",
    "                #print('x:', x.size())\n",
    "                #print('prevVal:', prevVal.size())\n",
    "                height, width = x.size()[2:]\n",
    "                resizeHeight, resizeWidth = prevVal.size()[2:]\n",
    "                \n",
    "                max_x = width - resizeWidth\n",
    "                max_y = height - resizeHeight\n",
    "\n",
    "                cornerX = np.random.randint(0, max_x)\n",
    "                cornerY = np.random.randint(0, max_y)\n",
    "                \n",
    "                smallX = x[:, :, cornerY:cornerY + resizeHeight, cornerX:cornerX + resizeWidth]\n",
    "                layerOutputs[name] = group.forward(prevVal, smallX)\n",
    "            else:\n",
    "                layerOutputs[name] = group.forward(prevVal)\n",
    "            prevVal = layerOutputs[name].clone()\n",
    "            \n",
    "        return layerOutputs['f']\n",
    "        \n",
    "net = Net(3, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.layers[0][1].block[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for p in net.parameters():\n",
    "    n_params = np.prod(list(p.data.shape)).item()\n",
    "    count += n_params\n",
    "    print(p.data)\n",
    "print(f'total params: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.RMSprop(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For early stopping, use blocks of epochs (say size 3), and a window (say size 10) of how far to look in the past.\n",
    "# Then, compare the average loss on the current block to the block in the past. Another idea would be compare the variances.\n",
    "# If the fraction is not sufficiently small, halt.\n",
    "\n",
    "max_epochs = 100\n",
    "# Should be stated as a fraction of the previous error\n",
    "#max_frac = 0.999\n",
    "#window = 10 # How many epochs in the past to compare to\n",
    "#block = 5 # What size block of epochs to use\n",
    "\n",
    "learnFreq = 10\n",
    "batch_multiplier = 4\n",
    "\n",
    "epoch_training_loss = []\n",
    "epoch_val_loss = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"\\nOn epoch: \" + str(epoch))\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    net.train()\n",
    "    for inputs, labels in training_generator:\n",
    "        \n",
    "        inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "        \n",
    "        if count == 0:\n",
    "            optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            count = batch_multiplier\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).to(device)\n",
    "        loss = criterion(torch.squeeze(outputs), labels) / batch_multiplier\n",
    "        loss.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        count -=1\n",
    "        \n",
    "        loss = loss.detach()\n",
    "        inputs = inputs.detach()\n",
    "        outputs = outputs.detach()\n",
    "        \n",
    "        # print('Batch loss: ', loss.item())\n",
    "\n",
    "        #print('Outputs', torch.squeeze(outputs))\n",
    "        #print('Batch size: ' + str(len(inputs)))\n",
    "        # Multiply by the batch size and batch_multiplier (because earlier divided)\n",
    "        #running_loss += loss.item() * len(inputs) * batch_multiplier\n",
    "        #print('Batch average loss ' + str(loss.item()))\n",
    "    #training_loss = running_loss / training_set.__len__()\n",
    "    #print(\"Epoch training loss: \" + str(training_loss))\n",
    "    #epoch_training_loss.append(training_loss)\n",
    "    if epoch % learnFreq == 0 or epoch == (max_epochs - 1):\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for i, dataset in enumerate([training_set, validation_set]):\n",
    "                if i == 0:\n",
    "                    print('\\nEpoch training results ')\n",
    "                else:\n",
    "                    print('\\nEpoch validation results ')\n",
    "                MSE = 0\n",
    "                avgAbsDev = 0\n",
    "                for sample in dataset.ids:\n",
    "                    X, y = dataset.__getitem__(sample)\n",
    "                    X = X.unsqueeze(0) # Add fake batch dimension\n",
    "                    X = X.to(device).float()\n",
    "        \n",
    "                    yHat = net(X).to(device)\n",
    "                    yHat = yHat.to('cpu')\n",
    "                    MSE += torch.norm(y - yHat)**2 / np.product(y.numpy().shape)\n",
    "                    #avgAbsDev += np.abs(yHat - y)\n",
    "        \n",
    "                #print('Sample: ' + str(sample))\n",
    "                #print('y: ' + str(y))\n",
    "                #print('yHat: ' + str(yHat))\n",
    "                MSE /= len(dataset.ids)\n",
    "                #avgAbsDev /= len(dataset.ids)\n",
    "                print('RMSE on dataset: ' + str(np.sqrt(MSE)))\n",
    "                #print('Avg Abs Dev on dataset: ' + str(avgAbsDev))\n",
    "                if i == 0:\n",
    "                    epoch_training_loss.append(MSE)\n",
    "                else:\n",
    "                    epoch_val_loss.append(MSE)\n",
    "        \n",
    "# for epoch in range(max_epochs):\n",
    "#     print(\"\\nOn epoch: \" + str(epoch))\n",
    "        \n",
    "#     net.train()\n",
    "#     for inputs, labels in training_generator:\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "#         print('inputs.shape: ', inputs.size())\n",
    "        \n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs.float())\n",
    "#         print('outputs.shape: ', outputs.size())\n",
    "#         print('labels.shape: ', labels.float().size())\n",
    "#         loss = criterion(torch.squeeze(outputs), labels.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print('Batch Loss: ' + str(loss.item()))\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "#         val_loss = 0\n",
    "#         net.eval()\n",
    "#         for ind in validation_set.ids:\n",
    "#             X, y = validation_set.__getitem__(ind)\n",
    "#             X = X.unsqueeze(0) # Add fake batch dimension\n",
    "#             yHat = net(X.float())\n",
    "#             val_loss += torch.norm(y - yHat)**2 / np.product(y.numpy().shape)\n",
    "#         val_loss /= validation_set.__len__()\n",
    "#         epoch_val_loss.append(val_loss)\n",
    "#     print(\"Epoch validation loss: \" + str(val_loss))\n",
    "        \n",
    "#     if len(epoch_val_loss) >= window + block + 1:\n",
    "#         latestBlock = np.mean(epoch_val_loss[-1:-1-block])\n",
    "#         earlierBlock = np.mean(epoch_val_loss[-1-window:-1-window-block])\n",
    "        \n",
    "#         # latestBlock must be sufficiently smaller than earlierBlock\n",
    "#         if latestBlock / earlierBlock > max_frac:\n",
    "#             print('Converged')\n",
    "#             pdb.set_trace()\n",
    "#             break\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i, dataset in enumerate([training_set, validation_set]):\n",
    "        if i == 0:\n",
    "            print('\\nTraining results ')\n",
    "        else:\n",
    "            print('\\nValidation results ')\n",
    "        MSE = 0\n",
    "        for sample in dataset.ids:\n",
    "            X, y = dataset.__getitem__(sample)\n",
    "            \n",
    "            X = X.to(device).unsqueeze(0) # Add fake batch dimension\n",
    "            yHat = net(X.float()).to(device)\n",
    "            yHat = yHat.to('cpu')\n",
    "            imshow(X.to('cpu'), 10000)\n",
    "            imshow(y, 10000)\n",
    "            imshow(yHat, 10000)\n",
    "            print(yHat)\n",
    "            # squared frobenius norm\n",
    "            MSE += torch.norm(y - yHat)**2 / np.product(y.numpy().shape)\n",
    "        MSE /= validation_set.__len__()\n",
    "    print('RMSE on dataset: ' + str(np.sqrt(MSE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "plt.figure()\n",
    "plt.plot(range(max_epochs), epoch_training_loss, range(max_epochs), epoch_val_loss)\n",
    "plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
