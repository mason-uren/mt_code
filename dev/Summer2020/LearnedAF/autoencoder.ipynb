{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pdb\n",
    "import math\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def get_random_crop(image, crop_height, crop_width):\n",
    "\n",
    "    max_x = image.shape[1] - crop_width\n",
    "    max_y = image.shape[0] - crop_height\n",
    "\n",
    "    x = np.random.randint(0, max_x)\n",
    "    y = np.random.randint(0, max_y)\n",
    "\n",
    "    crop = image[y: y + crop_height, x: x + crop_width]\n",
    "\n",
    "    return crop, x, y\n",
    "\n",
    "def searchForFocus(filename, substring):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read()\n",
    "        location = data.find(substring)\n",
    "        croppedStr = data[location+len(substring):]\n",
    "        # Split at spaces and find first number\n",
    "        for word in croppedStr.split(): # Split at spaces\n",
    "            # Delete any commas    \n",
    "            word = word.replace(',', \"\")\n",
    "            try:\n",
    "                focusPosition = int(word)\n",
    "                return focusPosition\n",
    "            except ValueError:\n",
    "                continue\n",
    "    file.close()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    # ids indicates what subfolders (samples) to access\n",
    "    def __init__(self, foldername, subfolderPrefix, ids):\n",
    "        self.foldername = foldername\n",
    "        self.subfolderPrefix = subfolderPrefix\n",
    "        self.ids = ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sampleFoldername = self.foldername + '/' + self.subfolderPrefix + str(index)\n",
    "        \n",
    "        # H, W\n",
    "        cropSize = (640, 640)\n",
    "        \n",
    "        images = []\n",
    "        for i, prefix in enumerate(['before', 'after']):\n",
    "        \n",
    "            # Load in image as [0,1] array\n",
    "            image = cv2.imread(sampleFoldername + '/' + prefix + str(index) + '.tif', 0) * 1 / 255.0\n",
    "\n",
    "            # Shift it so is from [-1,1]\n",
    "            image *= 2\n",
    "            image -= 1\n",
    "            \n",
    "            if i == 0:\n",
    "                # Randomly crop the image\n",
    "                image, cornerX, cornerY = get_random_crop(image, cropSize[0], cropSize[1])\n",
    "            else:\n",
    "                # Crop the label image to the same region as the input\n",
    "                image = image[cornerY:cornerY + cropSize[0], cornerX:cornerX + cropSize[1]]\n",
    "            \n",
    "            temp = torch.from_numpy(image)\n",
    "            if i == 0:\n",
    "                temp = temp.unsqueeze(0) # Add fake first dimension to specify 1-channel\n",
    "            images.append(temp)\n",
    "            \n",
    "        return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "params = {'batch_size': 2,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}\n",
    "\n",
    "# Randomly partition the full list into a training set and validation set\n",
    "numSamples = 100 # total number of samples collected\n",
    "frac = 1/5 # fraction to be validation\n",
    "np.random.seed(0)\n",
    "permutedIds = np.random.permutation(range(numSamples))\n",
    "splitPoint = int((1-frac) * len(permutedIds))\n",
    "trainingIds = permutedIds[:splitPoint]\n",
    "valIds = permutedIds[splitPoint:]\n",
    "\n",
    "training_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', trainingIds)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "validation_set = Dataset('/home/aofeldman/Desktop/AFdataCollection', 'sample', valIds)\n",
    "#validation_generator = torch.utils.data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2        0.20392157 0.18823529 ... 0.45098039 0.45882353 0.44705882]\n",
      " [0.18823529 0.19215686 0.19607843 ... 0.41568627 0.42352941 0.41960784]\n",
      " [0.19215686 0.17647059 0.18823529 ... 0.36862745 0.37254902 0.39215686]\n",
      " ...\n",
      " [0.18823529 0.19215686 0.20784314 ... 0.03529412 0.05882353 0.03921569]\n",
      " [0.21176471 0.19607843 0.21176471 ... 0.01176471 0.03921569 0.04313725]\n",
      " [0.22352941 0.21568627 0.21568627 ... 0.05098039 0.05882353 0.0627451 ]]\n",
      "torch.Size([1, 640, 640])\n",
      "[[0.18431373 0.20784314 0.2        ... 0.04313725 0.07058824 0.07058824]\n",
      " [0.19607843 0.21568627 0.20392157 ... 0.04313725 0.05882353 0.05882353]\n",
      " [0.19215686 0.16862745 0.16470588 ... 0.04313725 0.05490196 0.0745098 ]\n",
      " ...\n",
      " [0.19215686 0.19607843 0.20392157 ... 0.04313725 0.05882353 0.03529412]\n",
      " [0.20392157 0.2        0.20392157 ... 0.01176471 0.03137255 0.05098039]\n",
      " [0.21176471 0.21568627 0.20784314 ... 0.02745098 0.05098039 0.0627451 ]]\n",
      "torch.Size([640, 640])\n"
     ]
    }
   ],
   "source": [
    "X, Y = training_set.__getitem__(1)\n",
    "\n",
    "def imshow(img,wait):\n",
    "    img = img.squeeze()\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    print(npimg)\n",
    "    #width = int(0.15 * npimg.shape[1])\n",
    "    #height = int(0.15 * npimg.shape[0])\n",
    "    #cv2.imshow(\"Hi\",cv2.resize(npimg, (width, height)))\n",
    "    cv2.imshow('hi', npimg)\n",
    "    cv2.waitKey(wait)\n",
    "    cv2.destroyAllWindows()\n",
    "imshow(X, 10000)\n",
    "print(X.shape)\n",
    "imshow(Y, 10000)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider placing dropout layers after conv2d layers (conv2d -> batchnorm2d -> leakyReLU -> dropout(p=0.1))\n",
    "# And also place after fully connected layers (linear -> leakyReLU -> dropout(p=0.3))\n",
    "# TODO: Should actually figure out appropriate amount of padding for layers \n",
    "\n",
    "net = nn.Sequential(\n",
    "    # Encoder section\n",
    "    \n",
    "    # Does not change channel dimensions\n",
    "    nn.Conv2d(1, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    # 1/4 channel dimensions\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    # Does not change channel dimensions\n",
    "    nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    # 1/4 channel dimensions\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    # Does not change channel dimensions\n",
    "    nn.Conv2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    # 1/4 channel dimensions\n",
    "    nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "    \n",
    "    # At this point:\n",
    "    # Each channel has dimensions\n",
    "    # H_out, W_out = (1/4)^3 * (H_in, W_in)\n",
    "    \n",
    "    # Decoder section\n",
    "    nn.ConvTranspose2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Upsample(scale_factor = 4, mode='bilinear'),\n",
    "    \n",
    "    nn.ConvTranspose2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Upsample(scale_factor = 4, mode='bilinear'),\n",
    "    \n",
    "    nn.ConvTranspose2d(4, 4, kernel_size=5, stride=1, padding=2),\n",
    "    nn.BatchNorm2d(4),\n",
    "    nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "    nn.Upsample(scale_factor = 4, mode='bilinear'),\n",
    "    \n",
    "#     nn.ConvTranspose2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "#     nn.BatchNorm2d(4),\n",
    "#     nn.LeakyReLU(negative_slope = 0.1, inplace=True),\n",
    "#     nn.Upsample(scale_factor = (2, 2)),\n",
    "    \n",
    "    nn.ConvTranspose2d(4, 1, kernel_size=3, stride=1, padding=1),\n",
    "    nn.Tanh(),\n",
    ")\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, kernel, leakySlope, poolSize, use_norm):\n",
    "        block = [nn.Conv2d(dim[0], dim[1], kernel_size=kernel, stride=1, padding= (kernel-1) // 2)]\n",
    "        \n",
    "        if use_norm:\n",
    "            block += [nn.BatchNorm2d(dim[1])]\n",
    "        block += [nn.LeakyReLU(negative_slope = leakySlope, inplace=True),\n",
    "                  nn.MaxPool2d(kernel_size=poolSize, stride=poolSize)]\n",
    "        \n",
    "        self.encoderBlock = nn.Sequential(*block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoderBlock(x)\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim, kernel, leakySlope, scale, use_norm):\n",
    "        block = [nn.ConvTransposed2d(dim[0], dim[1], kernel_size=kernel, stride=1, padding= (kernel-1) // 2)]\n",
    "        \n",
    "        if use_norm:\n",
    "            block += [nn.BatchNorm2d(dim[1])]\n",
    "        block += [nn.LeakyReLU(negative_slope = leakySlope, inplace=True),\n",
    "                  nn.Upsample(scale_factor = scale, mode = 'bilinear')]\n",
    "        \n",
    "        self.decoderBlock = nn.Sequential(*block)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoderBlock(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, numEncoder, numDecoder):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential([])\n",
    "        for i in range(numEncoder):\n",
    "            self.model = nn.Sequential(self.model, EncoderBlock(1, 4, 5, 0.1, 4, True)\n",
    "        for j in range(numDecoder):\n",
    "            self.model = nn.Sequential(self.model, DecoderBlock(1, 4, 5, 0.1, 4, True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "                                       \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 4, 5, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 1, 3, 3])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0896, -0.1148, -0.1917, -0.0993, -0.0427],\n",
      "          [ 0.1118,  0.1566,  0.1642, -0.1485, -0.1511],\n",
      "          [-0.0448, -0.0137, -0.1080,  0.0233, -0.1919],\n",
      "          [ 0.1708, -0.0452,  0.0264, -0.1029,  0.1297],\n",
      "          [-0.0015, -0.0838,  0.1368, -0.1938,  0.1623]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1647, -0.0594,  0.0275, -0.1991,  0.0152],\n",
      "          [ 0.1332,  0.0326,  0.1105, -0.1027,  0.0334],\n",
      "          [-0.0466,  0.0208, -0.0144,  0.1781,  0.0878],\n",
      "          [-0.1738,  0.0425, -0.0143, -0.1736, -0.0191],\n",
      "          [ 0.0367, -0.0522, -0.0127,  0.0433,  0.1296]]],\n",
      "\n",
      "\n",
      "        [[[-0.0949, -0.1031,  0.0034, -0.1936, -0.1275],\n",
      "          [ 0.0719, -0.1426, -0.0033,  0.0595, -0.1780],\n",
      "          [-0.0260,  0.0856, -0.1913, -0.1365,  0.0193],\n",
      "          [ 0.0905, -0.1401,  0.1196, -0.1332,  0.1922],\n",
      "          [-0.0111, -0.1348,  0.0926,  0.0061,  0.0548]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0282,  0.0165,  0.1225, -0.1845,  0.0910],\n",
      "          [ 0.1853,  0.1841,  0.0828, -0.1426,  0.1555],\n",
      "          [-0.1128, -0.1954,  0.0666,  0.0193, -0.0793],\n",
      "          [-0.0474, -0.1549, -0.1304, -0.0690,  0.0904],\n",
      "          [-0.0294,  0.0356, -0.1944,  0.0551, -0.1047]]]], device='cuda:0')\n",
      "tensor([ 0.0310, -0.0613,  0.1677,  0.0248], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[-0.0828, -0.0922, -0.0641, -0.0468,  0.0718],\n",
      "          [ 0.0249,  0.0567, -0.0522,  0.0616, -0.0641],\n",
      "          [ 0.0027,  0.0660, -0.0336, -0.0799,  0.0516],\n",
      "          [-0.0993, -0.0768, -0.0566, -0.0158, -0.0232],\n",
      "          [-0.0011,  0.0791, -0.0475, -0.0822,  0.0063]],\n",
      "\n",
      "         [[ 0.0272, -0.0099, -0.0173,  0.0389,  0.0163],\n",
      "          [ 0.0366,  0.0097, -0.0898, -0.0241, -0.0833],\n",
      "          [ 0.0007, -0.0164, -0.0831, -0.0690,  0.0496],\n",
      "          [ 0.0917, -0.0312,  0.0081, -0.0506, -0.0393],\n",
      "          [ 0.0097, -0.0313,  0.0101,  0.0544,  0.0160]],\n",
      "\n",
      "         [[ 0.0136,  0.0842, -0.0176, -0.0988, -0.0161],\n",
      "          [-0.0995, -0.0834, -0.0760, -0.0888, -0.0198],\n",
      "          [ 0.0792,  0.0694,  0.0386, -0.0603, -0.0310],\n",
      "          [-0.0179,  0.0401,  0.0656,  0.0959, -0.0472],\n",
      "          [-0.0870, -0.0290,  0.0682,  0.0320, -0.0592]],\n",
      "\n",
      "         [[-0.0187,  0.0315, -0.0775, -0.0877, -0.0129],\n",
      "          [ 0.0698, -0.0697,  0.0690, -0.0569, -0.0524],\n",
      "          [ 0.0981,  0.0918, -0.0808, -0.0146,  0.0692],\n",
      "          [ 0.0193, -0.0873, -0.0198, -0.0497,  0.0996],\n",
      "          [ 0.0795,  0.0422, -0.0710,  0.0215,  0.0768]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0653,  0.0608,  0.0305,  0.0576,  0.0981],\n",
      "          [ 0.0593, -0.0846,  0.0062, -0.0309, -0.0111],\n",
      "          [-0.0608, -0.0204,  0.0818, -0.0506,  0.0995],\n",
      "          [-0.0564, -0.0005, -0.0371,  0.0754,  0.0739],\n",
      "          [-0.0973, -0.0193, -0.0266,  0.0796,  0.0833]],\n",
      "\n",
      "         [[-0.0352,  0.0695,  0.0471, -0.0900,  0.0608],\n",
      "          [ 0.0570,  0.0897,  0.0717,  0.0292, -0.0286],\n",
      "          [-0.0744, -0.0111, -0.0802, -0.0179,  0.0194],\n",
      "          [ 0.0435, -0.0222,  0.0457,  0.0216, -0.0737],\n",
      "          [-0.0110, -0.0292, -0.0466,  0.0085, -0.0089]],\n",
      "\n",
      "         [[ 0.0029, -0.0162, -0.0519, -0.0197, -0.0788],\n",
      "          [-0.0078,  0.0631,  0.0124,  0.0361,  0.0727],\n",
      "          [-0.0664,  0.0377, -0.0992,  0.0339,  0.0041],\n",
      "          [-0.0431, -0.0562,  0.0272, -0.0732,  0.0222],\n",
      "          [-0.0591,  0.0375,  0.0003,  0.0118,  0.0693]],\n",
      "\n",
      "         [[ 0.0123,  0.0717,  0.0096, -0.0781,  0.0602],\n",
      "          [ 0.0542, -0.0678,  0.0761,  0.0830,  0.0289],\n",
      "          [ 0.0403, -0.0176, -0.0177, -0.0665,  0.0672],\n",
      "          [ 0.0746, -0.0439,  0.0788,  0.0175,  0.0301],\n",
      "          [ 0.0800, -0.0600,  0.0431,  0.0686,  0.0882]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0143, -0.0758, -0.0131,  0.0597, -0.0190],\n",
      "          [ 0.0594,  0.0141, -0.0114,  0.0956, -0.0161],\n",
      "          [ 0.0795,  0.0786,  0.0124,  0.0598,  0.0213],\n",
      "          [-0.0002,  0.0024, -0.0334,  0.0916, -0.0349],\n",
      "          [ 0.0960, -0.0275, -0.0315, -0.0053, -0.0705]],\n",
      "\n",
      "         [[-0.0251, -0.0652,  0.0676,  0.0280, -0.0332],\n",
      "          [-0.0470, -0.0964, -0.0307, -0.0717, -0.0586],\n",
      "          [-0.0927,  0.0758, -0.0972, -0.0580,  0.0316],\n",
      "          [-0.0781,  0.0425,  0.0837, -0.0494, -0.0323],\n",
      "          [-0.0178,  0.0258, -0.0804,  0.0841, -0.0027]],\n",
      "\n",
      "         [[ 0.0894, -0.0668,  0.0235,  0.0372, -0.0147],\n",
      "          [ 0.0860,  0.0843, -0.0545,  0.0668, -0.0103],\n",
      "          [-0.0975, -0.0317,  0.0170, -0.0357, -0.0989],\n",
      "          [ 0.0158,  0.0466,  0.0530,  0.0922,  0.0542],\n",
      "          [ 0.0276,  0.0505, -0.0257,  0.0681, -0.0023]],\n",
      "\n",
      "         [[ 0.0551, -0.0322,  0.0020,  0.0331, -0.0972],\n",
      "          [ 0.0499, -0.0765,  0.0278, -0.0094, -0.0725],\n",
      "          [ 0.0749, -0.0394,  0.0535, -0.0923,  0.0992],\n",
      "          [ 0.0652,  0.0981,  0.0853,  0.0918, -0.0759],\n",
      "          [-0.0267, -0.0770,  0.0009, -0.0289,  0.0952]]],\n",
      "\n",
      "\n",
      "        [[[-0.0330, -0.0302,  0.0130, -0.0316,  0.0418],\n",
      "          [-0.0684, -0.0080,  0.0755,  0.0581, -0.0297],\n",
      "          [-0.0927, -0.0285,  0.0484, -0.0114,  0.0817],\n",
      "          [ 0.0959,  0.0905,  0.0071, -0.0778,  0.0982],\n",
      "          [-0.0345,  0.0858,  0.0073,  0.0332, -0.0287]],\n",
      "\n",
      "         [[ 0.0768, -0.0477, -0.0580, -0.0491,  0.0545],\n",
      "          [-0.0603, -0.0409, -0.0781, -0.0720, -0.0839],\n",
      "          [-0.0547,  0.0620, -0.0885, -0.0004, -0.0869],\n",
      "          [ 0.0336, -0.0750, -0.0222,  0.0601, -0.0349],\n",
      "          [-0.0228, -0.0395, -0.0670,  0.0355, -0.0294]],\n",
      "\n",
      "         [[ 0.0384,  0.0126,  0.0404, -0.0656,  0.0302],\n",
      "          [-0.0347, -0.0025, -0.0395,  0.0548,  0.0022],\n",
      "          [-0.0784, -0.0721,  0.0314, -0.0076,  0.0094],\n",
      "          [ 0.0276, -0.0988, -0.0816, -0.0792, -0.0712],\n",
      "          [-0.0850,  0.0209,  0.0500, -0.0128, -0.0591]],\n",
      "\n",
      "         [[-0.0275, -0.0045,  0.0470,  0.0882, -0.0596],\n",
      "          [ 0.0665,  0.0288,  0.0770,  0.0996,  0.0680],\n",
      "          [-0.0918, -0.0427, -0.0367,  0.0619,  0.0998],\n",
      "          [ 0.0211, -0.0600, -0.0597,  0.0788,  0.0165],\n",
      "          [ 0.0125,  0.0554,  0.0665, -0.0505,  0.0282]]]], device='cuda:0')\n",
      "tensor([-0.0747, -0.0638, -0.0403, -0.0841], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[ 0.0587,  0.0638, -0.0145,  0.0585,  0.0998],\n",
      "          [ 0.0376,  0.0929,  0.0254,  0.0029, -0.0760],\n",
      "          [-0.0775,  0.0615, -0.0311,  0.0660, -0.0709],\n",
      "          [ 0.0617, -0.0505, -0.0689,  0.0626,  0.0245],\n",
      "          [-0.0485, -0.0900,  0.0148,  0.0501, -0.0064]],\n",
      "\n",
      "         [[ 0.0350, -0.0148, -0.0741,  0.0239, -0.0588],\n",
      "          [ 0.0365, -0.0421, -0.0741, -0.0415, -0.0543],\n",
      "          [-0.0678,  0.0400,  0.0198,  0.0457, -0.0413],\n",
      "          [ 0.0428, -0.0478,  0.0334, -0.0702, -0.0473],\n",
      "          [ 0.0847, -0.0928,  0.0610, -0.0575, -0.0930]],\n",
      "\n",
      "         [[ 0.0662,  0.0140,  0.0369, -0.0121,  0.0282],\n",
      "          [-0.0797,  0.0773, -0.0743, -0.0068, -0.0966],\n",
      "          [-0.0564, -0.0366, -0.0026, -0.0534, -0.0907],\n",
      "          [-0.0080, -0.0440, -0.0190,  0.0925, -0.0977],\n",
      "          [ 0.0193,  0.0115, -0.0310,  0.0142, -0.0499]],\n",
      "\n",
      "         [[ 0.0074,  0.0445,  0.0713,  0.0943, -0.0935],\n",
      "          [-0.0132, -0.0558,  0.0156,  0.0265,  0.0279],\n",
      "          [-0.0563,  0.0423,  0.0421,  0.0280,  0.0579],\n",
      "          [ 0.0444,  0.0609, -0.0473, -0.0167,  0.0079],\n",
      "          [ 0.0364,  0.0521, -0.0991,  0.0430, -0.0887]]],\n",
      "\n",
      "\n",
      "        [[[-0.0092,  0.0427, -0.0730,  0.0821,  0.0803],\n",
      "          [-0.0880,  0.0510,  0.0821,  0.0048,  0.0585],\n",
      "          [ 0.0537,  0.0744, -0.0707,  0.0457,  0.0819],\n",
      "          [ 0.0080,  0.0424, -0.0887, -0.0295,  0.0052],\n",
      "          [-0.0022, -0.0511, -0.0821, -0.0298, -0.0045]],\n",
      "\n",
      "         [[ 0.0700,  0.0636,  0.0523, -0.0936, -0.0490],\n",
      "          [-0.0427,  0.0681,  0.0699, -0.0287,  0.0581],\n",
      "          [-0.0505,  0.0849, -0.0263,  0.0056, -0.0755],\n",
      "          [ 0.0746, -0.0698,  0.0254,  0.0499, -0.0127],\n",
      "          [-0.0989, -0.0120, -0.0190,  0.0068,  0.0491]],\n",
      "\n",
      "         [[-0.0977,  0.0774,  0.0267, -0.0495,  0.0383],\n",
      "          [ 0.0536, -0.0273, -0.0582, -0.0023, -0.0031],\n",
      "          [ 0.0263,  0.0124,  0.1000, -0.0863,  0.0090],\n",
      "          [-0.0429,  0.0795,  0.0770, -0.0680, -0.0059],\n",
      "          [ 0.0710,  0.0388, -0.0073,  0.0329,  0.0943]],\n",
      "\n",
      "         [[ 0.0353, -0.0900,  0.0760, -0.0300,  0.0509],\n",
      "          [ 0.0187,  0.0735,  0.0352, -0.0703, -0.0054],\n",
      "          [-0.0551, -0.0067,  0.0397, -0.0793, -0.0029],\n",
      "          [-0.0420, -0.0530,  0.0232, -0.0538, -0.0638],\n",
      "          [-0.0561,  0.0579,  0.0224,  0.0496,  0.0165]]],\n",
      "\n",
      "\n",
      "        [[[-0.0115, -0.0086,  0.0792,  0.0049, -0.0385],\n",
      "          [-0.0900,  0.0202, -0.0114, -0.0067, -0.0737],\n",
      "          [ 0.0302, -0.0705, -0.0479, -0.0922, -0.0662],\n",
      "          [ 0.0980,  0.0370,  0.0997,  0.0374, -0.0566],\n",
      "          [-0.0734,  0.0373,  0.0805, -0.0821, -0.0860]],\n",
      "\n",
      "         [[-0.0095, -0.0777,  0.0085, -0.0039,  0.0732],\n",
      "          [-0.0619, -0.0286,  0.0116, -0.0947, -0.0058],\n",
      "          [ 0.0705,  0.0022,  0.0984,  0.0648, -0.0274],\n",
      "          [ 0.0259, -0.0795,  0.0196,  0.0418,  0.0892],\n",
      "          [ 0.0276, -0.0667,  0.0194,  0.0046,  0.0530]],\n",
      "\n",
      "         [[ 0.0780,  0.0247, -0.0306,  0.0047, -0.0983],\n",
      "          [-0.0154,  0.0703, -0.0594,  0.0378,  0.0306],\n",
      "          [ 0.0440, -0.0064,  0.0197, -0.0833,  0.0549],\n",
      "          [ 0.0656, -0.0315,  0.0042,  0.0950,  0.0713],\n",
      "          [ 0.0579,  0.0405,  0.0741, -0.0197, -0.0443]],\n",
      "\n",
      "         [[-0.0257, -0.0491,  0.0845,  0.0379,  0.0573],\n",
      "          [ 0.0420,  0.0067, -0.0690,  0.0280, -0.0929],\n",
      "          [ 0.0748, -0.0656, -0.0101, -0.0281,  0.0692],\n",
      "          [-0.0420, -0.0878,  0.0180, -0.0407,  0.0195],\n",
      "          [-0.0939,  0.0934,  0.0810, -0.0440, -0.0936]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0535, -0.0746, -0.0291, -0.0683,  0.0932],\n",
      "          [ 0.0035, -0.0741, -0.0157, -0.0304,  0.0276],\n",
      "          [ 0.0656, -0.0344, -0.0143, -0.0419, -0.0465],\n",
      "          [-0.0789,  0.0235,  0.0414,  0.0713,  0.0310],\n",
      "          [-0.0825,  0.0649, -0.0807, -0.0785,  0.0570]],\n",
      "\n",
      "         [[ 0.0350, -0.0576, -0.0510, -0.0289, -0.0292],\n",
      "          [-0.0725,  0.0432,  0.0162,  0.0038, -0.0514],\n",
      "          [ 0.0028,  0.0014,  0.0648,  0.0993,  0.0008],\n",
      "          [-0.0268,  0.0427, -0.0429,  0.0232, -0.0518],\n",
      "          [-0.0491,  0.0738,  0.0267, -0.0425, -0.0943]],\n",
      "\n",
      "         [[ 0.0126,  0.0406,  0.0933,  0.0924, -0.0938],\n",
      "          [ 0.0352, -0.0539, -0.0511,  0.0896, -0.0747],\n",
      "          [-0.0102,  0.0349,  0.0863, -0.0835,  0.0852],\n",
      "          [-0.0836,  0.0525,  0.0684,  0.0788, -0.0795],\n",
      "          [-0.0925, -0.0811,  0.0160,  0.0767,  0.0601]],\n",
      "\n",
      "         [[ 0.0501, -0.0568, -0.0145,  0.0951, -0.0072],\n",
      "          [-0.0771,  0.0201,  0.0942,  0.0319,  0.0605],\n",
      "          [-0.0188, -0.0674,  0.0960,  0.0865, -0.0267],\n",
      "          [-0.0059, -0.0540, -0.0929,  0.0758,  0.0246],\n",
      "          [ 0.0802, -0.0283, -0.0908,  0.0826,  0.0148]]]], device='cuda:0')\n",
      "tensor([-0.0700, -0.0038, -0.0936,  0.0532], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[ 8.8043e-02, -5.6251e-02, -4.9872e-02,  5.4718e-02,  3.1246e-02],\n",
      "          [-9.1413e-02, -1.1914e-04,  8.5646e-02,  6.4649e-02, -6.6941e-02],\n",
      "          [ 5.0550e-02,  5.5589e-02, -5.3525e-02, -4.4458e-02, -7.8761e-03],\n",
      "          [ 4.0321e-02, -4.6743e-02, -9.1196e-02,  6.9251e-02, -1.7362e-02],\n",
      "          [ 3.7943e-02, -2.7303e-02,  1.0950e-02, -1.4668e-02, -6.1357e-02]],\n",
      "\n",
      "         [[ 6.5244e-02,  4.9558e-02,  5.8741e-02, -1.4407e-02,  4.3619e-02],\n",
      "          [ 7.4099e-02, -3.4155e-02, -1.8374e-02, -4.7755e-02,  4.8077e-02],\n",
      "          [-5.9165e-02, -6.1143e-02, -9.0314e-02, -8.6257e-02,  8.4904e-02],\n",
      "          [-7.4263e-02,  1.6501e-02, -5.5757e-02,  1.3819e-02, -8.4948e-02],\n",
      "          [-7.2823e-03,  5.3451e-02,  7.1067e-02, -9.5233e-02,  8.0077e-02]],\n",
      "\n",
      "         [[-2.5610e-02,  3.6315e-02,  5.1887e-02, -1.6089e-02,  4.2015e-02],\n",
      "          [ 6.0757e-02,  6.2710e-02,  8.3955e-02,  7.6279e-02,  8.2415e-02],\n",
      "          [-1.1586e-02,  9.1631e-02,  8.0593e-02, -3.0377e-02, -9.7085e-02],\n",
      "          [ 1.8109e-02,  2.1618e-02, -4.9470e-02,  7.3411e-02,  8.4537e-02],\n",
      "          [ 3.9551e-02,  5.0503e-02, -7.8323e-02, -2.4209e-02, -1.8839e-02]],\n",
      "\n",
      "         [[-6.1352e-02, -4.5313e-02,  3.2391e-02,  7.1802e-02,  4.4958e-02],\n",
      "          [ 5.9191e-02,  7.0202e-03,  9.1101e-02,  1.6292e-02, -6.7229e-02],\n",
      "          [ 1.2220e-02, -7.7934e-03, -7.9649e-02, -9.8987e-02, -2.7312e-02],\n",
      "          [-6.7686e-02, -2.5310e-02,  9.2187e-02, -2.0188e-02, -1.7949e-02],\n",
      "          [-6.1491e-02, -5.2077e-02,  9.2765e-02, -6.6252e-02, -5.8016e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4036e-02,  2.8446e-04, -1.5183e-02, -2.4776e-02, -8.3560e-02],\n",
      "          [-7.2134e-02,  4.5456e-02,  2.0343e-02,  8.3684e-02,  6.3931e-02],\n",
      "          [ 8.4175e-02,  9.1876e-03,  3.7531e-02, -1.5028e-02, -1.6239e-03],\n",
      "          [-8.5382e-02, -3.2647e-03, -6.0756e-02, -5.5955e-02,  1.7289e-02],\n",
      "          [ 7.3648e-02,  3.0359e-03,  9.4485e-05,  2.5438e-02, -6.5167e-02]],\n",
      "\n",
      "         [[ 2.1877e-02,  3.8927e-03, -8.9820e-02, -6.4397e-02,  3.6474e-02],\n",
      "          [ 8.3189e-02,  6.5549e-02, -9.0977e-02,  4.3949e-02, -2.3600e-02],\n",
      "          [-2.2910e-02, -6.9041e-02,  4.5060e-03, -6.8032e-02, -7.6008e-02],\n",
      "          [ 4.0626e-02,  4.2098e-02, -1.6764e-02, -3.6143e-02, -1.0478e-04],\n",
      "          [-9.4662e-02, -6.8376e-02, -7.4249e-02,  4.3098e-02, -9.1682e-03]],\n",
      "\n",
      "         [[ 8.0190e-02, -2.5760e-02, -5.5488e-03,  1.8236e-02,  8.5841e-02],\n",
      "          [-6.5857e-02,  6.9390e-02,  9.9620e-03,  7.4337e-04, -3.3922e-02],\n",
      "          [-5.3625e-02,  7.7076e-02, -4.9685e-02,  6.3783e-02, -5.0184e-02],\n",
      "          [-6.4558e-02, -3.8578e-02, -7.7715e-02,  3.7321e-02, -4.9531e-02],\n",
      "          [-9.8412e-02,  6.0796e-02, -6.3571e-03,  7.4992e-02, -6.5631e-02]],\n",
      "\n",
      "         [[ 9.9877e-03,  4.5144e-02, -8.9867e-02, -9.5830e-02, -2.8476e-02],\n",
      "          [ 2.3689e-02,  8.2272e-02,  5.5936e-02,  1.8953e-02, -7.8517e-03],\n",
      "          [-4.9838e-03, -9.2026e-02,  6.1139e-02, -7.5241e-03, -7.6158e-03],\n",
      "          [ 5.1968e-02,  7.5845e-03,  2.2654e-03, -9.8849e-02, -4.9524e-02],\n",
      "          [ 9.1503e-02,  9.5391e-02, -3.4666e-02, -6.3137e-02,  3.3883e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2751e-03,  3.6256e-02, -5.0164e-02, -1.5328e-02,  6.2314e-02],\n",
      "          [-8.4066e-02,  4.9301e-03,  2.4530e-02,  3.7267e-02, -1.2224e-02],\n",
      "          [ 3.8357e-02,  6.0611e-02, -6.2980e-02, -3.4465e-02,  5.6750e-02],\n",
      "          [-9.3897e-02,  5.2355e-02, -5.6180e-02, -7.6899e-02, -3.1041e-02],\n",
      "          [-5.3534e-02, -9.4850e-02, -9.1241e-02, -9.9858e-02, -9.1067e-02]],\n",
      "\n",
      "         [[ 9.4480e-02,  6.6492e-02, -8.5310e-02,  1.3661e-02, -5.2566e-02],\n",
      "          [-5.7066e-02,  1.4786e-02,  2.2010e-02, -1.0789e-02,  6.0393e-02],\n",
      "          [-8.7214e-02, -6.5144e-02,  4.2212e-02,  6.6403e-02,  7.8378e-03],\n",
      "          [ 6.2657e-02,  1.0641e-02, -1.1720e-02, -4.5256e-02, -4.6541e-02],\n",
      "          [ 1.3273e-02,  7.9888e-02, -4.8297e-02,  9.7779e-02, -4.5965e-02]],\n",
      "\n",
      "         [[-5.6577e-02,  8.9495e-02, -4.2533e-02,  4.9332e-02, -8.4605e-02],\n",
      "          [ 2.9886e-02,  1.7935e-02,  1.0200e-02, -5.0378e-02,  6.1964e-02],\n",
      "          [-3.7679e-02,  5.5767e-02, -8.9153e-02,  7.3916e-02,  9.4967e-03],\n",
      "          [ 5.1206e-02, -7.8484e-02,  5.0068e-02, -4.9038e-02,  6.1699e-02],\n",
      "          [ 9.0239e-03,  2.9329e-03,  5.1346e-02,  6.5117e-02, -5.0213e-02]],\n",
      "\n",
      "         [[ 9.5657e-02, -8.0393e-02, -6.6978e-02,  4.0853e-02, -3.1250e-02],\n",
      "          [-5.3211e-03,  6.4641e-02, -3.1165e-02,  8.0771e-02,  5.2265e-02],\n",
      "          [ 8.1074e-02,  7.7991e-02, -4.3034e-02, -4.5861e-03, -5.8320e-02],\n",
      "          [ 7.7629e-02, -7.1767e-02,  6.7174e-02,  1.8164e-02, -6.3098e-02],\n",
      "          [-8.0029e-02, -5.9949e-02,  5.5132e-03,  6.7338e-02, -8.5844e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1786e-02, -5.8739e-02, -5.0449e-02,  6.3376e-02,  9.3280e-02],\n",
      "          [ 6.6448e-02,  9.7477e-03,  8.5712e-02,  4.4505e-02,  4.8419e-02],\n",
      "          [ 9.5206e-02,  6.4669e-02, -9.6675e-02,  4.8786e-02, -2.8520e-02],\n",
      "          [-1.7046e-02, -7.1058e-02,  6.8423e-02,  2.9673e-02,  1.4504e-02],\n",
      "          [-4.0172e-02, -6.7467e-02,  3.1308e-02,  8.9694e-02,  6.4960e-02]],\n",
      "\n",
      "         [[-7.3087e-02, -9.8382e-02,  8.6807e-02, -7.9642e-03, -8.3389e-02],\n",
      "          [ 3.0047e-02,  2.1895e-03,  5.1204e-02, -6.2473e-02,  9.4226e-03],\n",
      "          [-5.1165e-02,  8.0496e-02, -4.1123e-02,  2.2078e-02, -5.9464e-02],\n",
      "          [ 8.6936e-02, -2.6408e-02,  3.1507e-03,  3.3353e-02,  9.9301e-02],\n",
      "          [-9.4580e-02,  8.7127e-02,  1.8107e-02,  6.4519e-02,  4.2679e-02]],\n",
      "\n",
      "         [[ 2.2594e-02,  4.5633e-02, -5.0915e-02, -7.7184e-02,  6.8183e-02],\n",
      "          [-7.4904e-02, -6.6105e-02, -2.8142e-02, -2.2228e-02, -2.9840e-02],\n",
      "          [ 9.5969e-02,  7.8213e-02,  1.4084e-02,  9.4816e-02, -3.0997e-02],\n",
      "          [ 5.1607e-02, -6.4869e-02, -5.6813e-02, -3.2377e-02, -7.1470e-02],\n",
      "          [-9.5085e-02, -5.7862e-02, -2.7310e-02, -7.1871e-02, -4.5318e-02]],\n",
      "\n",
      "         [[-4.1884e-02,  2.0172e-02, -4.0395e-02,  9.3611e-02,  6.3972e-02],\n",
      "          [ 6.1922e-02, -5.7854e-02,  4.9676e-02, -9.4374e-02, -3.2037e-02],\n",
      "          [-7.9698e-02, -7.6248e-02, -4.3714e-02, -8.5283e-03,  5.7336e-02],\n",
      "          [-9.1661e-02, -8.3782e-02, -9.3556e-03, -8.8310e-02,  5.8765e-02],\n",
      "          [ 9.7396e-02, -8.3849e-02, -7.7919e-02, -7.7154e-02, -2.2134e-02]]]],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0423, -0.0844,  0.0026, -0.0072], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[-0.0819,  0.0276, -0.0282, -0.0013,  0.0605],\n",
      "          [ 0.0923,  0.0998,  0.0809, -0.0685,  0.0511],\n",
      "          [ 0.0854,  0.0479, -0.0039,  0.0512,  0.0710],\n",
      "          [ 0.0485,  0.0061,  0.0853,  0.0570, -0.0190],\n",
      "          [-0.0023,  0.0367,  0.0518,  0.0401,  0.0958]],\n",
      "\n",
      "         [[-0.0184,  0.0926,  0.0038,  0.0739,  0.0285],\n",
      "          [-0.0270, -0.0448,  0.0870,  0.0947,  0.0235],\n",
      "          [ 0.0091, -0.0897,  0.0588, -0.0247,  0.0627],\n",
      "          [-0.0753,  0.0794, -0.0556, -0.0270, -0.0382],\n",
      "          [-0.0483, -0.0462, -0.0391, -0.0781, -0.0735]],\n",
      "\n",
      "         [[-0.0580, -0.0165, -0.0233, -0.0671,  0.0353],\n",
      "          [ 0.0448, -0.0700, -0.0824,  0.0632,  0.0248],\n",
      "          [-0.0840, -0.0122, -0.0320, -0.0436,  0.0982],\n",
      "          [ 0.0250, -0.0273,  0.0456,  0.0156, -0.0639],\n",
      "          [ 0.0861, -0.0587,  0.0463, -0.0995, -0.0728]],\n",
      "\n",
      "         [[ 0.0688, -0.0344, -0.0633,  0.0674,  0.0746],\n",
      "          [ 0.0066, -0.0991, -0.0948, -0.0486, -0.0130],\n",
      "          [ 0.0735,  0.0530, -0.0913,  0.0474, -0.0061],\n",
      "          [ 0.0384, -0.0416,  0.0384,  0.0922,  0.0677],\n",
      "          [-0.0026, -0.0416, -0.0569, -0.0430,  0.0451]]],\n",
      "\n",
      "\n",
      "        [[[-0.0250, -0.0562, -0.0159,  0.0276,  0.0604],\n",
      "          [-0.0550, -0.0052,  0.0123, -0.0424,  0.0677],\n",
      "          [ 0.0469,  0.0942,  0.0262, -0.0134,  0.0841],\n",
      "          [-0.0579, -0.0979, -0.0631, -0.0965,  0.0011],\n",
      "          [ 0.0772, -0.0934, -0.0846,  0.0878, -0.0681]],\n",
      "\n",
      "         [[ 0.0339, -0.0255, -0.0805,  0.0257,  0.0872],\n",
      "          [ 0.0093, -0.0213, -0.0032,  0.0010,  0.0528],\n",
      "          [ 0.0031, -0.0157,  0.0454, -0.0976, -0.0886],\n",
      "          [-0.0798, -0.0258, -0.0503, -0.0245, -0.0576],\n",
      "          [ 0.0451,  0.0205, -0.0948,  0.0134, -0.0897]],\n",
      "\n",
      "         [[-0.0905,  0.0646, -0.0347, -0.0725, -0.0955],\n",
      "          [-0.0946,  0.0645, -0.0044,  0.0319,  0.0872],\n",
      "          [ 0.0470,  0.0379, -0.0857,  0.0581, -0.0232],\n",
      "          [ 0.0291,  0.0049, -0.0920,  0.0616,  0.0385],\n",
      "          [-0.0821,  0.0742,  0.0519,  0.0383,  0.0102]],\n",
      "\n",
      "         [[ 0.0316, -0.0913, -0.0609, -0.0685, -0.0323],\n",
      "          [-0.0103,  0.0313, -0.0671, -0.0169,  0.0785],\n",
      "          [ 0.0329, -0.0209,  0.0122,  0.0157,  0.0893],\n",
      "          [ 0.0613,  0.0816,  0.0150,  0.0726,  0.0005],\n",
      "          [ 0.0131,  0.0013, -0.0503, -0.0802,  0.0930]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0038, -0.0893, -0.0393,  0.0643, -0.0581],\n",
      "          [ 0.0304, -0.0321, -0.0793,  0.0837,  0.0722],\n",
      "          [ 0.0959, -0.0377, -0.0263,  0.0057,  0.0167],\n",
      "          [ 0.0323,  0.0709, -0.0095,  0.0161,  0.0925],\n",
      "          [ 0.0831,  0.0481, -0.0740,  0.0048, -0.0357]],\n",
      "\n",
      "         [[ 0.0462, -0.0592,  0.0431,  0.0294, -0.0938],\n",
      "          [ 0.0895, -0.0586,  0.0100,  0.0456,  0.0204],\n",
      "          [-0.0377,  0.0791, -0.0244, -0.0981,  0.0662],\n",
      "          [ 0.0383, -0.0556,  0.0641,  0.0208, -0.0448],\n",
      "          [-0.0630, -0.0884, -0.0736, -0.0523, -0.0157]],\n",
      "\n",
      "         [[-0.0573, -0.0198, -0.0985,  0.0277,  0.0956],\n",
      "          [-0.0900, -0.0328, -0.0396, -0.0365,  0.0625],\n",
      "          [ 0.0654,  0.0904,  0.0666, -0.0946,  0.0476],\n",
      "          [-0.0540, -0.0032,  0.0175,  0.0598, -0.0285],\n",
      "          [ 0.0020,  0.0262, -0.0316,  0.0349, -0.0375]],\n",
      "\n",
      "         [[-0.0595, -0.0725, -0.0625, -0.0018, -0.0266],\n",
      "          [ 0.0754,  0.0137,  0.0909, -0.0368, -0.0540],\n",
      "          [-0.0144, -0.0274,  0.0637, -0.0558, -0.0344],\n",
      "          [-0.0812,  0.0478, -0.0821,  0.0596,  0.0766],\n",
      "          [-0.0066,  0.0463,  0.0703, -0.0580,  0.0247]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0663, -0.0353,  0.0763, -0.0136,  0.0630],\n",
      "          [-0.0461,  0.0511,  0.0401,  0.0111, -0.0253],\n",
      "          [ 0.0836, -0.0110,  0.0490, -0.0030,  0.0773],\n",
      "          [-0.0739,  0.0711, -0.0272, -0.0652, -0.0151],\n",
      "          [ 0.0598,  0.0592,  0.0827, -0.0415, -0.0947]],\n",
      "\n",
      "         [[ 0.0494,  0.0633,  0.0112, -0.0710, -0.0924],\n",
      "          [ 0.0960, -0.0343,  0.0064,  0.0344, -0.0376],\n",
      "          [-0.0950, -0.0415, -0.0063, -0.0854,  0.0212],\n",
      "          [-0.0326,  0.0803, -0.0625, -0.0610, -0.0187],\n",
      "          [-0.0170,  0.0062, -0.0095,  0.0053,  0.0779]],\n",
      "\n",
      "         [[ 0.0452,  0.0551,  0.0478,  0.0423,  0.0340],\n",
      "          [ 0.0170, -0.0182,  0.0064,  0.0008,  0.0427],\n",
      "          [-0.0242,  0.0041,  0.0615,  0.0946, -0.0830],\n",
      "          [ 0.0325,  0.0855, -0.0105,  0.0395,  0.0201],\n",
      "          [-0.0409,  0.0907, -0.0082, -0.0682, -0.0106]],\n",
      "\n",
      "         [[ 0.0427,  0.0203, -0.0913,  0.0666,  0.0390],\n",
      "          [-0.0402,  0.0696,  0.0649,  0.0582, -0.0075],\n",
      "          [-0.0866,  0.0189,  0.0850, -0.0927, -0.0217],\n",
      "          [-0.0652,  0.0983, -0.0440,  0.0254, -0.0032],\n",
      "          [-0.0932,  0.0156, -0.0549,  0.0416,  0.0167]]]], device='cuda:0')\n",
      "tensor([-0.0048, -0.0292,  0.0579, -0.0788], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[ 0.0178,  0.0292, -0.0026, -0.0974,  0.0714],\n",
      "          [-0.0645, -0.0497, -0.0406, -0.0103, -0.0791],\n",
      "          [-0.0917,  0.0576,  0.0644,  0.0485, -0.0054],\n",
      "          [-0.0313, -0.0303,  0.0800,  0.0211, -0.0583],\n",
      "          [ 0.0965,  0.0262, -0.0954, -0.0515, -0.0972]],\n",
      "\n",
      "         [[ 0.0658, -0.0333, -0.0566, -0.0847,  0.0625],\n",
      "          [-0.0662,  0.0607,  0.0456,  0.0582,  0.0792],\n",
      "          [ 0.0837,  0.0772,  0.0444, -0.0077,  0.0087],\n",
      "          [ 0.0389,  0.0336,  0.0526, -0.0116,  0.0804],\n",
      "          [ 0.0098, -0.0938,  0.0134, -0.0327, -0.0955]],\n",
      "\n",
      "         [[-0.0521,  0.0729,  0.0341,  0.0638, -0.0651],\n",
      "          [ 0.0736,  0.0572,  0.0777,  0.0301,  0.0057],\n",
      "          [ 0.0284, -0.0912, -0.0541, -0.0690, -0.0847],\n",
      "          [-0.0554, -0.0950, -0.0378, -0.0607, -0.0804],\n",
      "          [ 0.0035, -0.0539,  0.0282, -0.0515,  0.0400]],\n",
      "\n",
      "         [[ 0.0598, -0.0304, -0.0496,  0.0934,  0.0770],\n",
      "          [ 0.0865,  0.0371,  0.0022,  0.0155, -0.0136],\n",
      "          [-0.0017, -0.0805,  0.0892, -0.0909, -0.0721],\n",
      "          [ 0.0307,  0.0976, -0.0095, -0.0484,  0.0058],\n",
      "          [-0.0867, -0.0839,  0.0278, -0.0397,  0.0769]]],\n",
      "\n",
      "\n",
      "        [[[-0.0948,  0.0482, -0.0645,  0.0790,  0.0713],\n",
      "          [-0.0773,  0.0411, -0.0889,  0.0249,  0.0558],\n",
      "          [ 0.0844, -0.0476,  0.0550,  0.0057, -0.0804],\n",
      "          [ 0.0595, -0.0584,  0.0586,  0.0018,  0.0255],\n",
      "          [-0.0041,  0.0780,  0.0376, -0.0184,  0.0600]],\n",
      "\n",
      "         [[ 0.0961,  0.0705,  0.0371,  0.0585, -0.0238],\n",
      "          [-0.0634,  0.0779, -0.0716,  0.0751,  0.0162],\n",
      "          [-0.0366, -0.0065, -0.0143,  0.0369,  0.0683],\n",
      "          [ 0.0019, -0.0804, -0.0840,  0.0822,  0.0828],\n",
      "          [-0.0749, -0.0061,  0.0453,  0.0055,  0.0709]],\n",
      "\n",
      "         [[-0.0432,  0.0431, -0.0961, -0.0162,  0.0713],\n",
      "          [-0.0981,  0.0411,  0.0687,  0.0281, -0.0579],\n",
      "          [ 0.0307,  0.0328,  0.0693, -0.0140,  0.0539],\n",
      "          [-0.0867, -0.0133, -0.0520, -0.0846, -0.0459],\n",
      "          [-0.0191,  0.0415, -0.0419, -0.0725, -0.0985]],\n",
      "\n",
      "         [[-0.0886,  0.0480, -0.0524, -0.0808,  0.0618],\n",
      "          [ 0.0037,  0.0633,  0.0684, -0.0158,  0.0381],\n",
      "          [-0.0655,  0.0005,  0.0440,  0.0769, -0.0368],\n",
      "          [ 0.0612, -0.0278,  0.0785,  0.0717,  0.0629],\n",
      "          [ 0.0129,  0.0966,  0.0211,  0.0689, -0.0508]]],\n",
      "\n",
      "\n",
      "        [[[-0.0139, -0.0205,  0.0127,  0.0820,  0.0704],\n",
      "          [ 0.0994,  0.0764,  0.0896,  0.0048, -0.0096],\n",
      "          [-0.0135,  0.0979,  0.0984, -0.0732,  0.0788],\n",
      "          [ 0.0249,  0.0839, -0.0495, -0.0671, -0.0234],\n",
      "          [-0.0029, -0.0666, -0.0063,  0.0463, -0.0402]],\n",
      "\n",
      "         [[ 0.0219,  0.0141,  0.0378, -0.0461,  0.0210],\n",
      "          [ 0.0127,  0.0971, -0.0300,  0.0523,  0.0782],\n",
      "          [-0.0458,  0.0998, -0.0376,  0.0324,  0.0117],\n",
      "          [ 0.0755, -0.0413,  0.0503, -0.0086, -0.0530],\n",
      "          [-0.0754,  0.0318, -0.0432, -0.0747,  0.0795]],\n",
      "\n",
      "         [[ 0.0022, -0.0644,  0.0952,  0.0531, -0.0392],\n",
      "          [-0.0105,  0.0072,  0.0791, -0.0112,  0.0566],\n",
      "          [ 0.0080,  0.0614,  0.0863,  0.0998, -0.0020],\n",
      "          [ 0.0990,  0.0691,  0.0337, -0.0969,  0.0691],\n",
      "          [-0.0037,  0.0203, -0.0915, -0.0900, -0.0075]],\n",
      "\n",
      "         [[ 0.0657,  0.0171, -0.0261, -0.0422,  0.0981],\n",
      "          [ 0.0025, -0.0538, -0.0631,  0.0176, -0.0797],\n",
      "          [ 0.0317,  0.0118, -0.0200,  0.0434, -0.0916],\n",
      "          [-0.0724, -0.0446,  0.0317, -0.0097,  0.0428],\n",
      "          [ 0.0078,  0.0455, -0.0259, -0.0355,  0.0405]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0897, -0.0484,  0.0816, -0.0165, -0.0074],\n",
      "          [-0.0294, -0.0762, -0.0188,  0.0778,  0.0402],\n",
      "          [ 0.0107, -0.0025, -0.0115,  0.0445, -0.0304],\n",
      "          [-0.0355, -0.0675, -0.0554,  0.0118,  0.0570],\n",
      "          [ 0.0932,  0.0475,  0.0465,  0.0092, -0.0788]],\n",
      "\n",
      "         [[ 0.0993, -0.0129, -0.0060,  0.0152, -0.0165],\n",
      "          [ 0.0735, -0.0885, -0.0615, -0.0833,  0.0906],\n",
      "          [-0.0573,  0.0311,  0.0479, -0.0085,  0.0984],\n",
      "          [ 0.0123, -0.0044, -0.0824,  0.0526, -0.0794],\n",
      "          [ 0.0198,  0.0322,  0.0460,  0.0453,  0.0136]],\n",
      "\n",
      "         [[-0.0178,  0.0099,  0.0427, -0.0598, -0.0409],\n",
      "          [-0.0777, -0.0358,  0.0512,  0.0015,  0.0463],\n",
      "          [ 0.0295,  0.0074, -0.0811, -0.0691,  0.0547],\n",
      "          [-0.0014,  0.0198, -0.0239, -0.0731, -0.0405],\n",
      "          [ 0.0056, -0.0234,  0.0731, -0.0116,  0.0810]],\n",
      "\n",
      "         [[-0.0133, -0.0407,  0.0015, -0.0699, -0.0296],\n",
      "          [ 0.0402,  0.0352,  0.0007, -0.0583, -0.0690],\n",
      "          [-0.0266, -0.0243, -0.0466,  0.0801, -0.0740],\n",
      "          [ 0.0746,  0.0773,  0.0918, -0.0428,  0.0158],\n",
      "          [ 0.0867,  0.0958, -0.0547, -0.0237,  0.0041]]]], device='cuda:0')\n",
      "tensor([ 0.0843, -0.0468, -0.0733,  0.0364], device='cuda:0')\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([[[[ 0.3031, -0.0864,  0.0358],\n",
      "          [ 0.3280,  0.0179,  0.0781],\n",
      "          [ 0.2853, -0.1808, -0.2411]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1450,  0.0479, -0.3120],\n",
      "          [ 0.1852,  0.1231, -0.3206],\n",
      "          [-0.2890,  0.3057, -0.1156]]],\n",
      "\n",
      "\n",
      "        [[[-0.0500, -0.0911, -0.2902],\n",
      "          [ 0.3141,  0.0837,  0.3105],\n",
      "          [ 0.0576, -0.0347, -0.2050]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1997,  0.2219, -0.1324],\n",
      "          [-0.2893, -0.0476,  0.0996],\n",
      "          [-0.1504, -0.2421,  0.0997]]]], device='cuda:0')\n",
      "tensor([0.1394], device='cuda:0')\n",
      "total params: 2209\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for p in net.parameters():\n",
    "    n_params = np.prod(list(p.data.shape)).item()\n",
    "    count += n_params\n",
    "    print(p.data)\n",
    "print(f'total params: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.RMSprop(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aofeldman/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3118: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.6046, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5912, dtype=torch.float64)\n",
      "\n",
      "On epoch: 1\n",
      "\n",
      "On epoch: 2\n",
      "\n",
      "On epoch: 3\n",
      "\n",
      "On epoch: 4\n",
      "\n",
      "On epoch: 5\n",
      "\n",
      "On epoch: 6\n",
      "\n",
      "On epoch: 7\n",
      "\n",
      "On epoch: 8\n",
      "\n",
      "On epoch: 9\n",
      "\n",
      "On epoch: 10\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5820, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5966, dtype=torch.float64)\n",
      "\n",
      "On epoch: 11\n",
      "\n",
      "On epoch: 12\n",
      "\n",
      "On epoch: 13\n",
      "\n",
      "On epoch: 14\n",
      "\n",
      "On epoch: 15\n",
      "\n",
      "On epoch: 16\n",
      "\n",
      "On epoch: 17\n",
      "\n",
      "On epoch: 18\n",
      "\n",
      "On epoch: 19\n",
      "\n",
      "On epoch: 20\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5777, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5927, dtype=torch.float64)\n",
      "\n",
      "On epoch: 21\n",
      "\n",
      "On epoch: 22\n",
      "\n",
      "On epoch: 23\n",
      "\n",
      "On epoch: 24\n",
      "\n",
      "On epoch: 25\n",
      "\n",
      "On epoch: 26\n",
      "\n",
      "On epoch: 27\n",
      "\n",
      "On epoch: 28\n",
      "\n",
      "On epoch: 29\n",
      "\n",
      "On epoch: 30\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5677, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5618, dtype=torch.float64)\n",
      "\n",
      "On epoch: 31\n",
      "\n",
      "On epoch: 32\n",
      "\n",
      "On epoch: 33\n",
      "\n",
      "On epoch: 34\n",
      "\n",
      "On epoch: 35\n",
      "\n",
      "On epoch: 36\n",
      "\n",
      "On epoch: 37\n",
      "\n",
      "On epoch: 38\n",
      "\n",
      "On epoch: 39\n",
      "\n",
      "On epoch: 40\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5783, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5403, dtype=torch.float64)\n",
      "\n",
      "On epoch: 41\n",
      "\n",
      "On epoch: 42\n",
      "\n",
      "On epoch: 43\n",
      "\n",
      "On epoch: 44\n",
      "\n",
      "On epoch: 45\n",
      "\n",
      "On epoch: 46\n",
      "\n",
      "On epoch: 47\n",
      "\n",
      "On epoch: 48\n",
      "\n",
      "On epoch: 49\n",
      "\n",
      "On epoch: 50\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5859, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5731, dtype=torch.float64)\n",
      "\n",
      "On epoch: 51\n",
      "\n",
      "On epoch: 52\n",
      "\n",
      "On epoch: 53\n",
      "\n",
      "On epoch: 54\n",
      "\n",
      "On epoch: 55\n",
      "\n",
      "On epoch: 56\n",
      "\n",
      "On epoch: 57\n",
      "\n",
      "On epoch: 58\n",
      "\n",
      "On epoch: 59\n",
      "\n",
      "On epoch: 60\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5769, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5748, dtype=torch.float64)\n",
      "\n",
      "On epoch: 61\n",
      "\n",
      "On epoch: 62\n",
      "\n",
      "On epoch: 63\n",
      "\n",
      "On epoch: 64\n",
      "\n",
      "On epoch: 65\n",
      "\n",
      "On epoch: 66\n",
      "\n",
      "On epoch: 67\n",
      "\n",
      "On epoch: 68\n",
      "\n",
      "On epoch: 69\n",
      "\n",
      "On epoch: 70\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5758, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5464, dtype=torch.float64)\n",
      "\n",
      "On epoch: 71\n",
      "\n",
      "On epoch: 72\n",
      "\n",
      "On epoch: 73\n",
      "\n",
      "On epoch: 74\n",
      "\n",
      "On epoch: 75\n",
      "\n",
      "On epoch: 76\n",
      "\n",
      "On epoch: 77\n",
      "\n",
      "On epoch: 78\n",
      "\n",
      "On epoch: 79\n",
      "\n",
      "On epoch: 80\n",
      "\n",
      "Epoch training results \n",
      "RMSE on dataset: tensor(0.5706, dtype=torch.float64)\n",
      "\n",
      "Epoch validation results \n",
      "RMSE on dataset: tensor(0.5621, dtype=torch.float64)\n",
      "\n",
      "On epoch: 81\n",
      "\n",
      "On epoch: 82\n",
      "\n",
      "On epoch: 83\n",
      "\n",
      "On epoch: 84\n",
      "\n",
      "On epoch: 85\n",
      "\n",
      "On epoch: 86\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6b43031b0661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For early stopping, use blocks of epochs (say size 3), and a window (say size 10) of how far to look in the past.\n",
    "# Then, compare the average loss on the current block to the block in the past. Another idea would be compare the variances.\n",
    "# If the fraction is not sufficiently small, halt.\n",
    "\n",
    "max_epochs = 100\n",
    "# Should be stated as a fraction of the previous error\n",
    "#max_frac = 0.999\n",
    "#window = 10 # How many epochs in the past to compare to\n",
    "#block = 5 # What size block of epochs to use\n",
    "\n",
    "learnFreq = 10\n",
    "batch_multiplier = 1\n",
    "\n",
    "epoch_training_loss = []\n",
    "epoch_val_loss = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"\\nOn epoch: \" + str(epoch))\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    net.train()\n",
    "    for inputs, labels in training_generator:\n",
    "        \n",
    "        inputs, labels = inputs.to(device).float(), labels.to(device).float()\n",
    "        \n",
    "        if count == 0:\n",
    "            optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            count = batch_multiplier\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).to(device)\n",
    "        loss = criterion(torch.squeeze(outputs), labels) / batch_multiplier\n",
    "        loss.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        count -=1\n",
    "        \n",
    "        loss = loss.detach()\n",
    "        inputs = inputs.detach()\n",
    "        outputs = outputs.detach()\n",
    "        \n",
    "        #print('Outputs', torch.squeeze(outputs))\n",
    "        #print('Batch size: ' + str(len(inputs)))\n",
    "        # Multiply by the batch size and batch_multiplier (because earlier divided)\n",
    "        #running_loss += loss.item() * len(inputs) * batch_multiplier\n",
    "        #print('Batch average loss ' + str(loss.item()))\n",
    "    #training_loss = running_loss / training_set.__len__()\n",
    "    #print(\"Epoch training loss: \" + str(training_loss))\n",
    "    #epoch_training_loss.append(training_loss)\n",
    "    if epoch % learnFreq == 0 or epoch == (max_epochs - 1):\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for i, dataset in enumerate([training_set, validation_set]):\n",
    "                if i == 0:\n",
    "                    print('\\nEpoch training results ')\n",
    "                else:\n",
    "                    print('\\nEpoch validation results ')\n",
    "                MSE = 0\n",
    "                avgAbsDev = 0\n",
    "                for sample in dataset.ids:\n",
    "                    X, y = dataset.__getitem__(sample)\n",
    "                    X = X.unsqueeze(0) # Add fake batch dimension\n",
    "                    X = X.to(device).float()\n",
    "        \n",
    "                    yHat = net(X).to(device)\n",
    "                    yHat = yHat.to('cpu')\n",
    "                    MSE += torch.norm(y - yHat)**2 / np.product(y.numpy().shape)\n",
    "                    #avgAbsDev += np.abs(yHat - y)\n",
    "        \n",
    "                #print('Sample: ' + str(sample))\n",
    "                #print('y: ' + str(y))\n",
    "                #print('yHat: ' + str(yHat))\n",
    "                MSE /= len(dataset.ids)\n",
    "                #avgAbsDev /= len(dataset.ids)\n",
    "                print('RMSE on dataset: ' + str(np.sqrt(MSE)))\n",
    "                #print('Avg Abs Dev on dataset: ' + str(avgAbsDev))\n",
    "                if i == 0:\n",
    "                    epoch_training_loss.append(MSE)\n",
    "                else:\n",
    "                    epoch_val_loss.append(MSE)\n",
    "        \n",
    "# for epoch in range(max_epochs):\n",
    "#     print(\"\\nOn epoch: \" + str(epoch))\n",
    "        \n",
    "#     net.train()\n",
    "#     for inputs, labels in training_generator:\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "#         print('inputs.shape: ', inputs.size())\n",
    "        \n",
    "#         # forward + backward + optimize\n",
    "#         outputs = net(inputs.float())\n",
    "#         print('outputs.shape: ', outputs.size())\n",
    "#         print('labels.shape: ', labels.float().size())\n",
    "#         loss = criterion(torch.squeeze(outputs), labels.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print('Batch Loss: ' + str(loss.item()))\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "#         val_loss = 0\n",
    "#         net.eval()\n",
    "#         for ind in validation_set.ids:\n",
    "#             X, y = validation_set.__getitem__(ind)\n",
    "#             X = X.unsqueeze(0) # Add fake batch dimension\n",
    "#             yHat = net(X.float())\n",
    "#             val_loss += torch.norm(y - yHat)**2 / np.product(y.numpy().shape)\n",
    "#         val_loss /= validation_set.__len__()\n",
    "#         epoch_val_loss.append(val_loss)\n",
    "#     print(\"Epoch validation loss: \" + str(val_loss))\n",
    "        \n",
    "#     if len(epoch_val_loss) >= window + block + 1:\n",
    "#         latestBlock = np.mean(epoch_val_loss[-1:-1-block])\n",
    "#         earlierBlock = np.mean(epoch_val_loss[-1-window:-1-window-block])\n",
    "        \n",
    "#         # latestBlock must be sufficiently smaller than earlierBlock\n",
    "#         if latestBlock / earlierBlock > max_frac:\n",
    "#             print('Converged')\n",
    "#             pdb.set_trace()\n",
    "#             break\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training results \n",
      "[[0.58823529 0.59215686 0.58431373 ... 0.55686275 0.55686275 0.55686275]\n",
      " [0.58431373 0.58823529 0.58431373 ... 0.55686275 0.55686275 0.55686275]\n",
      " [0.57647059 0.58431373 0.58431373 ... 0.56078431 0.56078431 0.56078431]\n",
      " ...\n",
      " [0.52941176 0.53333333 0.52941176 ... 0.41568627 0.43529412 0.43921569]\n",
      " [0.51764706 0.5254902  0.52156863 ... 0.41960784 0.43921569 0.43921569]\n",
      " [0.51764706 0.52941176 0.52941176 ... 0.42745098 0.43921569 0.43921569]]\n",
      "[[0.10588235 0.06666667 0.05490196 ... 0.06666667 0.05098039 0.05490196]\n",
      " [0.10588235 0.07843137 0.05490196 ... 0.07843137 0.08235294 0.07843137]\n",
      " [0.07843137 0.10588235 0.08627451 ... 0.08235294 0.09411765 0.0627451 ]\n",
      " ...\n",
      " [0.16862745 0.21568627 0.37647059 ... 0.18431373 0.2        0.18823529]\n",
      " [0.12941176 0.20392157 0.36862745 ... 0.1254902  0.13333333 0.11372549]\n",
      " [0.1372549  0.20392157 0.33333333 ... 0.12156863 0.14509804 0.12156863]]\n",
      "[[0.33435106 0.34369275 0.3443289  ... 0.33058786 0.33043936 0.3297859 ]\n",
      " [0.3473851  0.36539707 0.36665708 ... 0.3408725  0.34053302 0.33830458]\n",
      " [0.3479029  0.3663897  0.367688   ... 0.34089923 0.3405498  0.33831888]\n",
      " ...\n",
      " [0.32762995 0.33406246 0.33395177 ... 0.33490875 0.33490628 0.33323517]\n",
      " [0.32765377 0.33388638 0.33377284 ... 0.33479732 0.33480927 0.33309627]\n",
      " [0.32462272 0.32638958 0.32619894 ... 0.32794803 0.32803166 0.32719412]]\n",
      "[[0.58431373 0.58823529 0.58039216 ... 0.60784314 0.60784314 0.61176471]\n",
      " [0.58823529 0.58823529 0.58039216 ... 0.60392157 0.60392157 0.60392157]\n",
      " [0.57647059 0.58039216 0.58823529 ... 0.61568627 0.60784314 0.60784314]\n",
      " ...\n",
      " [0.06666667 0.08627451 0.0627451  ... 0.07058824 0.06666667 0.06666667]\n",
      " [0.0745098  0.09411765 0.0627451  ... 0.04313725 0.05098039 0.04705882]\n",
      " [0.08627451 0.08235294 0.0627451  ... 0.04313725 0.04705882 0.04705882]]\n",
      "[[0.87843137 0.86666667 0.80784314 ... 0.74509804 0.78039216 0.78039216]\n",
      " [0.72156863 0.71764706 0.70588235 ... 0.78823529 0.74901961 0.73333333]\n",
      " [0.65098039 0.68627451 0.74117647 ... 0.88235294 0.82745098 0.80784314]\n",
      " ...\n",
      " [0.04705882 0.07058824 0.05098039 ... 0.0745098  0.05882353 0.05098039]\n",
      " [0.05490196 0.07843137 0.05882353 ... 0.05882353 0.04705882 0.04313725]\n",
      " [0.07843137 0.05098039 0.03137255 ... 0.05098039 0.04313725 0.05098039]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9213a01d999f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myHat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# squared frobenius norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-1d4fb050ca07>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img, wait)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#cv2.imshow(\"Hi\",cv2.resize(npimg, (width, height)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i, dataset in enumerate([training_set, validation_set]):\n",
    "        if i == 0:\n",
    "            print('\\nTraining results ')\n",
    "        else:\n",
    "            print('\\nValidation results ')\n",
    "        MSE = 0\n",
    "        for sample in dataset.ids:\n",
    "            X, y = dataset.__getitem__(sample)\n",
    "            \n",
    "            X = X.unsqueeze(0).to(device) # Add fake batch dimension\n",
    "            yHat = net(X.float())\n",
    "            \n",
    "            yHat = yHat.to('cpu')\n",
    "            \n",
    "            imshow(X.to('cpu'), 10000)\n",
    "            imshow(y, 10000)\n",
    "            imshow(yHat, 10000)\n",
    "            # squared frobenius norm\n",
    "            MSE += torch.norm(y - yHat)**2 / np.product(y.numpy().shape)\n",
    "        MSE /= validation_set.__len__()\n",
    "    print('RMSE on dataset: ' + str(np.sqrt(MSE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "plt.figure()\n",
    "plt.plot(range(max_epochs), epoch_training_loss, range(max_epochs), epoch_val_loss)\n",
    "plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
